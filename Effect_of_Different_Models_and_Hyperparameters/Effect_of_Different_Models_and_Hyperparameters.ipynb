{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AsadMunir\\AppData\\Local\\Temp\\ipykernel_14724\\748637648.py:12: DtypeWarning: Columns (10,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('ship_data.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler   \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, ReLU, PReLU, ELU, LeakyReLU, Dropout\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "X = grouped[[\"Distance_km\", 'Cordinates']]\n",
    "y = grouped[\"total_time_minutes\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sc=StandardScaler()\n",
    "\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(861, 6)\n",
      "(216, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AsadMunir\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 440943.3750 - mae: 554.4794 - val_loss: 488072.6875 - val_mae: 574.9362\n",
      "Epoch 2/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 431784.2500 - mae: 549.3959 - val_loss: 487634.4062 - val_mae: 574.5874\n",
      "Epoch 3/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 391545.7188 - mae: 513.7988 - val_loss: 487060.9375 - val_mae: 574.1373\n",
      "Epoch 4/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 379990.1250 - mae: 500.9593 - val_loss: 486259.0312 - val_mae: 573.5116\n",
      "Epoch 5/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 422603.1875 - mae: 536.5881 - val_loss: 485143.2500 - val_mae: 572.6664\n",
      "Epoch 6/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 422093.5312 - mae: 542.7581 - val_loss: 483675.0625 - val_mae: 571.5488\n",
      "Epoch 7/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 401549.0625 - mae: 532.1235 - val_loss: 481708.4062 - val_mae: 570.0825\n",
      "Epoch 8/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 407167.3750 - mae: 520.6077 - val_loss: 479106.9688 - val_mae: 568.1664\n",
      "Epoch 9/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 385285.5000 - mae: 514.4612 - val_loss: 475527.0625 - val_mae: 565.5511\n",
      "Epoch 10/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 387143.9688 - mae: 510.3697 - val_loss: 471158.6250 - val_mae: 562.3480\n",
      "Epoch 11/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 381963.3438 - mae: 500.2754 - val_loss: 465791.3125 - val_mae: 558.4360\n",
      "Epoch 12/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 366119.5000 - mae: 486.6775 - val_loss: 459567.6875 - val_mae: 553.8846\n",
      "Epoch 13/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 373861.3750 - mae: 500.1618 - val_loss: 452126.6250 - val_mae: 548.4600\n",
      "Epoch 14/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 370864.5625 - mae: 496.8552 - val_loss: 443605.0625 - val_mae: 542.2589\n",
      "Epoch 15/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 385493.6875 - mae: 507.3713 - val_loss: 433668.1250 - val_mae: 534.8906\n",
      "Epoch 16/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 359320.7812 - mae: 484.8184 - val_loss: 422716.4688 - val_mae: 526.6403\n",
      "Epoch 17/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 355455.7500 - mae: 481.2894 - val_loss: 410219.1250 - val_mae: 517.1922\n",
      "Epoch 18/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 320138.9062 - mae: 456.0493 - val_loss: 396862.2188 - val_mae: 506.7864\n",
      "Epoch 19/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 335548.3438 - mae: 459.0297 - val_loss: 382573.1562 - val_mae: 495.4931\n",
      "Epoch 20/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 312531.5312 - mae: 448.7453 - val_loss: 366700.8125 - val_mae: 482.7036\n",
      "Epoch 21/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 282295.4375 - mae: 420.3363 - val_loss: 350843.1562 - val_mae: 469.5139\n",
      "Epoch 22/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 280790.1250 - mae: 418.4749 - val_loss: 333840.2812 - val_mae: 454.9577\n",
      "Epoch 23/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 293966.6875 - mae: 415.4799 - val_loss: 317863.1250 - val_mae: 440.9839\n",
      "Epoch 24/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 273859.5938 - mae: 399.6170 - val_loss: 300890.8125 - val_mae: 425.6467\n",
      "Epoch 25/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 227894.9062 - mae: 365.7831 - val_loss: 284679.3125 - val_mae: 410.5742\n",
      "Epoch 26/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 235724.2656 - mae: 360.1827 - val_loss: 267608.5938 - val_mae: 394.4733\n",
      "Epoch 27/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 207215.5000 - mae: 342.0269 - val_loss: 252526.8281 - val_mae: 379.6037\n",
      "Epoch 28/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 236106.1406 - mae: 363.6038 - val_loss: 237173.1719 - val_mae: 364.6777\n",
      "Epoch 29/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 181394.8906 - mae: 312.3255 - val_loss: 222200.3594 - val_mae: 349.7770\n",
      "Epoch 30/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 194745.3594 - mae: 326.2791 - val_loss: 208071.7031 - val_mae: 335.7163\n",
      "Epoch 31/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 176019.4844 - mae: 323.4660 - val_loss: 194211.3281 - val_mae: 322.0895\n",
      "Epoch 32/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 191940.3594 - mae: 319.4228 - val_loss: 181680.4531 - val_mae: 310.0640\n",
      "Epoch 33/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 169557.6719 - mae: 305.5122 - val_loss: 170639.3906 - val_mae: 299.8882\n",
      "Epoch 34/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 146622.5781 - mae: 279.4226 - val_loss: 159646.6094 - val_mae: 289.5443\n",
      "Epoch 35/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 154270.5469 - mae: 303.9316 - val_loss: 149298.2500 - val_mae: 279.8331\n",
      "Epoch 36/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 135089.6562 - mae: 272.8062 - val_loss: 139540.6094 - val_mae: 270.4886\n",
      "Epoch 37/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 136295.7031 - mae: 272.9136 - val_loss: 132041.2188 - val_mae: 263.1416\n",
      "Epoch 38/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 136764.1406 - mae: 278.3978 - val_loss: 125136.9531 - val_mae: 256.2811\n",
      "Epoch 39/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 140681.1250 - mae: 287.6127 - val_loss: 117503.9844 - val_mae: 248.4667\n",
      "Epoch 40/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 138675.3906 - mae: 273.5441 - val_loss: 111765.3984 - val_mae: 242.4107\n",
      "Epoch 41/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 121394.5859 - mae: 253.7118 - val_loss: 106209.2656 - val_mae: 236.3804\n",
      "Epoch 42/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 119134.8984 - mae: 242.9861 - val_loss: 101570.6875 - val_mae: 231.0037\n",
      "Epoch 43/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 117232.5703 - mae: 255.4003 - val_loss: 97032.6406 - val_mae: 225.6011\n",
      "Epoch 44/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114876.4141 - mae: 252.2984 - val_loss: 93587.3125 - val_mae: 221.3100\n",
      "Epoch 45/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 117111.7031 - mae: 252.2194 - val_loss: 90460.7969 - val_mae: 217.3672\n",
      "Epoch 46/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 95846.7578 - mae: 231.6667 - val_loss: 86105.2344 - val_mae: 211.8116\n",
      "Epoch 47/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 96858.5000 - mae: 231.5338 - val_loss: 84024.7031 - val_mae: 208.7998\n",
      "Epoch 48/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 113352.6250 - mae: 243.2987 - val_loss: 81157.4453 - val_mae: 204.8610\n",
      "Epoch 49/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 106341.4453 - mae: 237.4052 - val_loss: 78283.3438 - val_mae: 201.1216\n",
      "Epoch 50/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 95814.8594 - mae: 233.9670 - val_loss: 76475.7031 - val_mae: 198.6082\n",
      "Epoch 51/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 104263.4922 - mae: 233.9929 - val_loss: 74188.7969 - val_mae: 195.3653\n",
      "Epoch 52/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 105956.1250 - mae: 238.8626 - val_loss: 73140.7031 - val_mae: 193.6330\n",
      "Epoch 53/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 116262.2969 - mae: 251.1670 - val_loss: 71917.9766 - val_mae: 191.7053\n",
      "Epoch 54/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 118966.7109 - mae: 244.4831 - val_loss: 70893.2578 - val_mae: 190.0958\n",
      "Epoch 55/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 103169.8359 - mae: 240.7308 - val_loss: 69823.6797 - val_mae: 188.3551\n",
      "Epoch 56/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 91581.0547 - mae: 224.2366 - val_loss: 69054.5000 - val_mae: 187.1149\n",
      "Epoch 57/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 94860.3828 - mae: 226.1598 - val_loss: 69056.2578 - val_mae: 186.9608\n",
      "Epoch 58/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 104485.7578 - mae: 227.0777 - val_loss: 67462.6094 - val_mae: 184.3531\n",
      "Epoch 59/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 93993.5156 - mae: 226.1339 - val_loss: 65853.2891 - val_mae: 181.7426\n",
      "Epoch 60/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 107284.0156 - mae: 240.8796 - val_loss: 64869.7773 - val_mae: 180.0662\n",
      "Epoch 61/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 100040.2656 - mae: 233.0850 - val_loss: 63521.5000 - val_mae: 177.8096\n",
      "Epoch 62/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 90961.7500 - mae: 230.7460 - val_loss: 62590.5898 - val_mae: 176.1612\n",
      "Epoch 63/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 90574.3906 - mae: 226.9696 - val_loss: 62281.9570 - val_mae: 175.5966\n",
      "Epoch 64/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 101257.0703 - mae: 240.8787 - val_loss: 62281.8398 - val_mae: 175.5276\n",
      "Epoch 65/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 85084.6562 - mae: 216.1808 - val_loss: 61675.4727 - val_mae: 174.4178\n",
      "Epoch 66/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 124329.9297 - mae: 252.4523 - val_loss: 61476.8438 - val_mae: 174.1364\n",
      "Epoch 67/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 101819.3359 - mae: 242.0099 - val_loss: 60542.7656 - val_mae: 172.3017\n",
      "Epoch 68/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 105188.4609 - mae: 236.0988 - val_loss: 59256.9961 - val_mae: 169.7427\n",
      "Epoch 69/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 95786.1328 - mae: 231.5004 - val_loss: 58742.4219 - val_mae: 168.5804\n",
      "Epoch 70/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 99144.5781 - mae: 229.6856 - val_loss: 59274.8711 - val_mae: 169.3814\n",
      "Epoch 71/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 96110.3750 - mae: 227.0129 - val_loss: 58984.0508 - val_mae: 168.7142\n",
      "Epoch 72/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 96501.5078 - mae: 229.9589 - val_loss: 59743.1562 - val_mae: 170.1994\n",
      "Epoch 73/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 96575.6797 - mae: 225.2940 - val_loss: 59987.3633 - val_mae: 170.5838\n",
      "Epoch 74/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 98486.4297 - mae: 230.0787 - val_loss: 59632.4570 - val_mae: 169.7049\n",
      "Epoch 75/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 83592.2188 - mae: 212.1250 - val_loss: 58933.9375 - val_mae: 168.3211\n",
      "Epoch 76/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 87334.0391 - mae: 218.0913 - val_loss: 57600.5000 - val_mae: 165.3079\n",
      "Epoch 77/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 114800.9531 - mae: 252.0705 - val_loss: 57474.6289 - val_mae: 164.9336\n",
      "Epoch 78/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 73347.4922 - mae: 209.5506 - val_loss: 58237.7422 - val_mae: 166.5581\n",
      "Epoch 79/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 84369.1875 - mae: 210.8575 - val_loss: 58350.1406 - val_mae: 166.7415\n",
      "Epoch 80/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 88947.8828 - mae: 215.6396 - val_loss: 58959.7070 - val_mae: 167.9353\n",
      "Epoch 81/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 95497.4453 - mae: 224.4230 - val_loss: 58723.1602 - val_mae: 167.3485\n",
      "Epoch 82/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 84411.6484 - mae: 204.9328 - val_loss: 58362.4492 - val_mae: 166.4514\n",
      "Epoch 83/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 101575.7031 - mae: 227.2672 - val_loss: 58670.1172 - val_mae: 167.1300\n",
      "Epoch 84/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 85106.8906 - mae: 215.2957 - val_loss: 58277.9297 - val_mae: 166.1463\n",
      "Epoch 85/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 89358.6875 - mae: 219.4453 - val_loss: 58629.3281 - val_mae: 166.7068\n",
      "Epoch 86/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 99155.4453 - mae: 227.4416 - val_loss: 58598.0664 - val_mae: 166.6546\n",
      "Epoch 87/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 94651.6250 - mae: 224.2168 - val_loss: 58298.5352 - val_mae: 165.8017\n",
      "Epoch 88/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 102918.7422 - mae: 230.7783 - val_loss: 58321.0664 - val_mae: 165.6064\n",
      "Epoch 89/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 100046.8984 - mae: 234.4903 - val_loss: 57602.5977 - val_mae: 163.8106\n",
      "Epoch 90/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 79864.4375 - mae: 205.5291 - val_loss: 56987.5312 - val_mae: 162.2679\n",
      "Epoch 91/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 86278.0078 - mae: 222.8723 - val_loss: 57811.8789 - val_mae: 164.3130\n",
      "Epoch 92/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 80760.1484 - mae: 211.7108 - val_loss: 58144.3281 - val_mae: 164.9993\n",
      "Epoch 93/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 94607.8359 - mae: 226.6772 - val_loss: 58216.7383 - val_mae: 165.1335\n",
      "Epoch 94/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 80905.9688 - mae: 202.3687 - val_loss: 58965.1367 - val_mae: 166.8103\n",
      "Epoch 95/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 99617.3984 - mae: 231.7009 - val_loss: 57773.6133 - val_mae: 163.9422\n",
      "Epoch 96/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 81589.7188 - mae: 212.3673 - val_loss: 56479.5938 - val_mae: 160.7245\n",
      "Epoch 97/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 86673.7422 - mae: 213.1918 - val_loss: 55651.6055 - val_mae: 158.6521\n",
      "Epoch 98/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 97413.9219 - mae: 224.1263 - val_loss: 55190.8164 - val_mae: 157.3834\n",
      "Epoch 99/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 88089.3125 - mae: 223.3938 - val_loss: 54717.3945 - val_mae: 155.9463\n",
      "Epoch 100/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 84009.6016 - mae: 215.2671 - val_loss: 54737.2148 - val_mae: 155.8983\n",
      "Epoch 101/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 88324.0156 - mae: 207.9667 - val_loss: 54822.9492 - val_mae: 156.0712\n",
      "Epoch 102/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 88011.8750 - mae: 220.2467 - val_loss: 54251.2773 - val_mae: 154.3647\n",
      "Epoch 103/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 84219.4219 - mae: 215.5473 - val_loss: 53971.3125 - val_mae: 153.9146\n",
      "Epoch 104/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 87084.2891 - mae: 220.7477 - val_loss: 54357.3906 - val_mae: 154.8322\n",
      "Epoch 105/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 83693.8281 - mae: 210.5290 - val_loss: 54863.2930 - val_mae: 156.1929\n",
      "Epoch 106/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 95052.9688 - mae: 215.6886 - val_loss: 55676.1562 - val_mae: 158.1197\n",
      "Epoch 107/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 79121.0312 - mae: 214.1663 - val_loss: 55286.6055 - val_mae: 156.7430\n",
      "Epoch 108/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 98059.5547 - mae: 225.0585 - val_loss: 55273.4102 - val_mae: 156.6769\n",
      "Epoch 109/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 87755.1719 - mae: 219.3134 - val_loss: 55390.1914 - val_mae: 157.0317\n",
      "Epoch 110/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 83734.8594 - mae: 214.5586 - val_loss: 54730.2812 - val_mae: 155.0961\n",
      "Epoch 111/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 85642.1719 - mae: 211.5984 - val_loss: 55260.3867 - val_mae: 156.6143\n",
      "Epoch 112/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 86041.3359 - mae: 224.5296 - val_loss: 55503.2148 - val_mae: 157.1431\n",
      "Epoch 113/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 95569.3750 - mae: 227.5003 - val_loss: 55975.1992 - val_mae: 158.3951\n",
      "Epoch 114/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 85875.2266 - mae: 219.6874 - val_loss: 55241.9062 - val_mae: 156.2778\n",
      "Epoch 115/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 92663.0547 - mae: 222.9522 - val_loss: 54391.0273 - val_mae: 153.8194\n",
      "Epoch 116/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 90519.0625 - mae: 220.9909 - val_loss: 54828.4219 - val_mae: 155.0423\n",
      "Epoch 117/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 85435.6875 - mae: 216.0161 - val_loss: 55404.1406 - val_mae: 156.7445\n",
      "Epoch 118/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 98589.9453 - mae: 224.7937 - val_loss: 56212.6992 - val_mae: 158.8298\n",
      "Epoch 119/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 83881.3047 - mae: 208.4571 - val_loss: 55967.8438 - val_mae: 158.2507\n",
      "Epoch 120/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 97617.3203 - mae: 216.4518 - val_loss: 55029.7891 - val_mae: 155.5797\n",
      "Epoch 121/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 76583.2109 - mae: 204.0659 - val_loss: 54958.1250 - val_mae: 155.3442\n",
      "Epoch 122/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 103673.7109 - mae: 228.3545 - val_loss: 55947.6133 - val_mae: 158.0078\n",
      "Epoch 123/1000\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 95521.7734 - mae: 224.6161 - val_loss: 55953.0312 - val_mae: 157.9192\n",
      "Epoch 123: early stopping\n",
      "Restoring model weights from the end of the best epoch: 103.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step \n",
      "Mean Absolute Error: 164.21793217129178\n",
      "Mean Squared Error: 52282.24659375457\n",
      "R-squared: 0.6758296736250311\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=X_train.shape[1])) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(units=3, activation='relu')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(1, activation='linear'))  \n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00001,  \n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True  # 'false' should be 'True'\n",
    ")\n",
    "final=model.fit(X_train,y_train, validation_split=0.33,batch_size=10,epochs=1000,callbacks=early_stopping)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AsadMunir\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 406840.2188 - mae: 521.5933 - val_loss: 488297.0312 - val_mae: 575.0574\n",
      "Epoch 2/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 414303.5938 - mae: 530.7039 - val_loss: 488230.6250 - val_mae: 575.0075\n",
      "Epoch 3/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 426385.3125 - mae: 544.7739 - val_loss: 488161.2812 - val_mae: 574.9561\n",
      "Epoch 4/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 423069.2812 - mae: 536.9020 - val_loss: 488090.0000 - val_mae: 574.9039\n",
      "Epoch 5/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 424800.4062 - mae: 541.6672 - val_loss: 488012.6875 - val_mae: 574.8479\n",
      "Epoch 6/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 412552.6250 - mae: 526.6822 - val_loss: 487937.2500 - val_mae: 574.7928\n",
      "Epoch 7/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 434243.8438 - mae: 545.5956 - val_loss: 487855.0938 - val_mae: 574.7335\n",
      "Epoch 8/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 389238.8125 - mae: 513.4286 - val_loss: 487766.3438 - val_mae: 574.6701\n",
      "Epoch 9/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 456038.7812 - mae: 559.4284 - val_loss: 487668.0000 - val_mae: 574.6018\n",
      "Epoch 10/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 415814.1250 - mae: 534.1799 - val_loss: 487567.5938 - val_mae: 574.5317\n",
      "Epoch 11/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 404023.8125 - mae: 522.8143 - val_loss: 487461.4375 - val_mae: 574.4571\n",
      "Epoch 12/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 407634.7812 - mae: 523.7484 - val_loss: 487343.8438 - val_mae: 574.3755\n",
      "Epoch 13/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 427161.9375 - mae: 540.2557 - val_loss: 487219.1562 - val_mae: 574.2886\n",
      "Epoch 14/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 458666.3125 - mae: 559.8658 - val_loss: 487082.8438 - val_mae: 574.1938\n",
      "Epoch 15/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 446236.4062 - mae: 547.8651 - val_loss: 486931.0938 - val_mae: 574.0898\n",
      "Epoch 16/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 415397.5625 - mae: 533.9712 - val_loss: 486773.7188 - val_mae: 573.9821\n",
      "Epoch 17/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 405800.0938 - mae: 521.6300 - val_loss: 486602.0625 - val_mae: 573.8658\n",
      "Epoch 18/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 400369.3125 - mae: 518.8112 - val_loss: 486417.7812 - val_mae: 573.7402\n",
      "Epoch 19/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 431928.2812 - mae: 553.0546 - val_loss: 486214.9062 - val_mae: 573.6040\n",
      "Epoch 20/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 417040.0000 - mae: 540.7235 - val_loss: 486003.3125 - val_mae: 573.4628\n",
      "Epoch 21/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 446637.3750 - mae: 554.0303 - val_loss: 485770.5000 - val_mae: 573.3087\n",
      "Epoch 22/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 455923.7812 - mae: 555.3118 - val_loss: 485516.4688 - val_mae: 573.1417\n",
      "Epoch 23/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 419264.5625 - mae: 535.4678 - val_loss: 485260.0625 - val_mae: 572.9723\n",
      "Epoch 24/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 440452.2812 - mae: 550.6422 - val_loss: 484970.2188 - val_mae: 572.7842\n",
      "Epoch 25/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 426364.0312 - mae: 539.8457 - val_loss: 484671.0938 - val_mae: 572.5886\n",
      "Epoch 26/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 444214.5938 - mae: 553.1788 - val_loss: 484341.6250 - val_mae: 572.3739\n",
      "Epoch 27/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 403407.9688 - mae: 520.7282 - val_loss: 484016.2188 - val_mae: 572.1594\n",
      "Epoch 28/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 414759.6250 - mae: 532.3869 - val_loss: 483658.2188 - val_mae: 571.9252\n",
      "Epoch 29/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 405177.7812 - mae: 528.0389 - val_loss: 483277.5312 - val_mae: 571.6767\n",
      "Epoch 30/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 419549.1250 - mae: 531.0385 - val_loss: 482870.1250 - val_mae: 571.4137\n",
      "Epoch 31/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 445641.8750 - mae: 552.9526 - val_loss: 482447.5000 - val_mae: 571.1409\n",
      "Epoch 32/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 397709.5938 - mae: 520.6505 - val_loss: 482004.2812 - val_mae: 570.8537\n",
      "Epoch 33/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 394689.2812 - mae: 514.8691 - val_loss: 481540.8125 - val_mae: 570.5532\n",
      "Epoch 34/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 441750.6250 - mae: 550.9772 - val_loss: 481040.6250 - val_mae: 570.2314\n",
      "Epoch 35/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 413063.6250 - mae: 531.9604 - val_loss: 480552.5938 - val_mae: 569.9149\n",
      "Epoch 36/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 418663.6250 - mae: 540.8272 - val_loss: 479999.0938 - val_mae: 569.5591\n",
      "Epoch 37/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 402831.4375 - mae: 519.6734 - val_loss: 479398.7500 - val_mae: 569.1738\n",
      "Epoch 38/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 414715.6250 - mae: 534.1177 - val_loss: 478807.7500 - val_mae: 568.7922\n",
      "Epoch 39/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 405441.3125 - mae: 525.6671 - val_loss: 478194.4688 - val_mae: 568.3972\n",
      "Epoch 40/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 427797.8438 - mae: 542.6290 - val_loss: 477508.3125 - val_mae: 567.9582\n",
      "Epoch 41/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 399091.1250 - mae: 513.0879 - val_loss: 476806.2812 - val_mae: 567.5062\n",
      "Epoch 42/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 399794.9062 - mae: 520.8922 - val_loss: 476041.1562 - val_mae: 567.0159\n",
      "Epoch 43/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 392635.0938 - mae: 515.8292 - val_loss: 475276.8125 - val_mae: 566.5217\n",
      "Epoch 44/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 417685.4688 - mae: 529.1422 - val_loss: 474481.1875 - val_mae: 566.0110\n",
      "Epoch 45/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 411929.3125 - mae: 529.4621 - val_loss: 473666.1250 - val_mae: 565.4836\n",
      "Epoch 46/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 391489.1562 - mae: 514.1458 - val_loss: 472848.9688 - val_mae: 564.9498\n",
      "Epoch 47/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 396981.6562 - mae: 518.3672 - val_loss: 471957.9062 - val_mae: 564.3786\n",
      "Epoch 48/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 420461.4375 - mae: 537.3773 - val_loss: 470978.6250 - val_mae: 563.7510\n",
      "Epoch 49/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 395362.2188 - mae: 522.5474 - val_loss: 470018.0312 - val_mae: 563.1310\n",
      "Epoch 50/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 395846.5938 - mae: 517.0637 - val_loss: 469018.1875 - val_mae: 562.4821\n",
      "Epoch 51/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 419729.3438 - mae: 537.9227 - val_loss: 467984.1250 - val_mae: 561.8124\n",
      "Epoch 52/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 393162.0000 - mae: 509.0735 - val_loss: 466948.8438 - val_mae: 561.1373\n",
      "Epoch 53/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 394214.1562 - mae: 517.0402 - val_loss: 465835.4375 - val_mae: 560.4155\n",
      "Epoch 54/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 387301.2188 - mae: 515.5686 - val_loss: 464670.9375 - val_mae: 559.6658\n",
      "Epoch 55/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 399398.0000 - mae: 522.5627 - val_loss: 463448.0312 - val_mae: 558.8768\n",
      "Epoch 56/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 406514.4688 - mae: 523.6663 - val_loss: 462237.7812 - val_mae: 558.0912\n",
      "Epoch 57/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 417669.2188 - mae: 527.0765 - val_loss: 460979.3750 - val_mae: 557.2748\n",
      "Epoch 58/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 365983.7812 - mae: 497.9680 - val_loss: 459708.4375 - val_mae: 556.4423\n",
      "Epoch 59/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 377428.9688 - mae: 504.0265 - val_loss: 458318.2188 - val_mae: 555.5417\n",
      "Epoch 60/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 395117.4062 - mae: 519.3795 - val_loss: 456870.7188 - val_mae: 554.5981\n",
      "Epoch 61/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 375817.7188 - mae: 505.5797 - val_loss: 455389.8438 - val_mae: 553.6312\n",
      "Epoch 62/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 379856.5938 - mae: 500.6839 - val_loss: 453906.2188 - val_mae: 552.6540\n",
      "Epoch 63/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 410385.6250 - mae: 529.5739 - val_loss: 452338.2500 - val_mae: 551.6302\n",
      "Epoch 64/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 380481.9375 - mae: 506.0554 - val_loss: 450721.6875 - val_mae: 550.5658\n",
      "Epoch 65/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 398462.9062 - mae: 523.4432 - val_loss: 449026.2500 - val_mae: 549.4548\n",
      "Epoch 66/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 389520.9688 - mae: 510.4085 - val_loss: 447383.8125 - val_mae: 548.3735\n",
      "Epoch 67/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 372817.5938 - mae: 501.0783 - val_loss: 445710.2188 - val_mae: 547.2649\n",
      "Epoch 68/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 368574.1875 - mae: 498.9044 - val_loss: 443905.5312 - val_mae: 546.0789\n",
      "Epoch 69/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 395218.8125 - mae: 516.1507 - val_loss: 442049.7500 - val_mae: 544.8595\n",
      "Epoch 70/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 388297.4375 - mae: 518.1109 - val_loss: 440154.0625 - val_mae: 543.6035\n",
      "Epoch 71/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 416328.5312 - mae: 536.1719 - val_loss: 438237.4375 - val_mae: 542.3290\n",
      "Epoch 72/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 385975.6250 - mae: 511.4611 - val_loss: 436229.2500 - val_mae: 540.9908\n",
      "Epoch 73/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 370181.1562 - mae: 502.9351 - val_loss: 434247.9688 - val_mae: 539.6639\n",
      "Epoch 74/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 382280.5938 - mae: 510.9432 - val_loss: 432122.6875 - val_mae: 538.2535\n",
      "Epoch 75/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 371316.3750 - mae: 497.6023 - val_loss: 430091.8750 - val_mae: 536.8911\n",
      "Epoch 76/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 361952.7812 - mae: 492.0061 - val_loss: 427966.7500 - val_mae: 535.4675\n",
      "Epoch 77/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 381617.4688 - mae: 508.7061 - val_loss: 425754.3125 - val_mae: 533.9870\n",
      "Epoch 78/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 389375.1875 - mae: 514.5948 - val_loss: 423521.3438 - val_mae: 532.4831\n",
      "Epoch 79/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 388572.9375 - mae: 512.3010 - val_loss: 421341.6562 - val_mae: 530.9939\n",
      "Epoch 80/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 352491.6250 - mae: 490.3403 - val_loss: 419127.4375 - val_mae: 529.4761\n",
      "Epoch 81/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 366510.1250 - mae: 493.7646 - val_loss: 416733.3125 - val_mae: 527.8477\n",
      "Epoch 82/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 323346.6562 - mae: 468.4486 - val_loss: 414354.4062 - val_mae: 526.2111\n",
      "Epoch 83/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 342171.7188 - mae: 480.4196 - val_loss: 411839.9062 - val_mae: 524.4940\n",
      "Epoch 84/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 366542.6250 - mae: 496.6429 - val_loss: 409306.7500 - val_mae: 522.7679\n",
      "Epoch 85/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 341593.4688 - mae: 464.7631 - val_loss: 406786.9688 - val_mae: 521.0388\n",
      "Epoch 86/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 346179.3125 - mae: 483.1438 - val_loss: 404150.9062 - val_mae: 519.2072\n",
      "Epoch 87/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 324774.7188 - mae: 461.2462 - val_loss: 401609.9375 - val_mae: 517.4308\n",
      "Epoch 88/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 331004.9375 - mae: 466.9181 - val_loss: 398946.7500 - val_mae: 515.5823\n",
      "Epoch 89/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 323886.5938 - mae: 462.7381 - val_loss: 396298.0625 - val_mae: 513.7225\n",
      "Epoch 90/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 357878.4375 - mae: 486.3844 - val_loss: 393560.8750 - val_mae: 511.8065\n",
      "Epoch 91/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 340450.0000 - mae: 477.8615 - val_loss: 390979.1562 - val_mae: 509.9803\n",
      "Epoch 92/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 358168.1562 - mae: 485.9618 - val_loss: 388220.6562 - val_mae: 508.0204\n",
      "Epoch 93/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 336212.2188 - mae: 478.5316 - val_loss: 385421.1250 - val_mae: 506.0122\n",
      "Epoch 94/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 320940.3438 - mae: 463.3324 - val_loss: 382576.6250 - val_mae: 503.9686\n",
      "Epoch 95/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 309339.6250 - mae: 451.1934 - val_loss: 379756.6875 - val_mae: 501.9259\n",
      "Epoch 96/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 331955.0312 - mae: 471.8791 - val_loss: 376806.5000 - val_mae: 499.8043\n",
      "Epoch 97/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 336246.1875 - mae: 472.4282 - val_loss: 373869.1250 - val_mae: 497.6664\n",
      "Epoch 98/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 328757.0625 - mae: 468.3765 - val_loss: 370833.0000 - val_mae: 495.4423\n",
      "Epoch 99/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 329242.7812 - mae: 464.1813 - val_loss: 367828.0000 - val_mae: 493.2352\n",
      "Epoch 100/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 312795.9375 - mae: 458.2724 - val_loss: 364795.8125 - val_mae: 490.9913\n",
      "Epoch 101/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 321483.2188 - mae: 464.1184 - val_loss: 361679.5312 - val_mae: 488.6834\n",
      "Epoch 102/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 307504.4688 - mae: 453.3025 - val_loss: 358604.6562 - val_mae: 486.3979\n",
      "Epoch 103/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 306727.8438 - mae: 448.6800 - val_loss: 355567.7188 - val_mae: 484.1386\n",
      "Epoch 104/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 307529.5938 - mae: 452.0282 - val_loss: 352425.2500 - val_mae: 481.7743\n",
      "Epoch 105/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 305014.3438 - mae: 450.3445 - val_loss: 349196.1562 - val_mae: 479.3532\n",
      "Epoch 106/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 296009.3438 - mae: 441.0219 - val_loss: 346034.6250 - val_mae: 476.9407\n",
      "Epoch 107/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 288431.5625 - mae: 436.2407 - val_loss: 342970.7500 - val_mae: 474.5949\n",
      "Epoch 108/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 292131.3125 - mae: 435.2729 - val_loss: 339795.5938 - val_mae: 472.1410\n",
      "Epoch 109/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 279018.1562 - mae: 430.0060 - val_loss: 336586.8438 - val_mae: 469.6563\n",
      "Epoch 110/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 294801.6562 - mae: 443.9461 - val_loss: 333402.6875 - val_mae: 467.1833\n",
      "Epoch 111/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 275523.2812 - mae: 421.4948 - val_loss: 330193.9375 - val_mae: 464.6725\n",
      "Epoch 112/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 273822.2500 - mae: 423.2229 - val_loss: 326938.4375 - val_mae: 462.1281\n",
      "Epoch 113/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 283570.6562 - mae: 422.7342 - val_loss: 323754.2500 - val_mae: 459.6169\n",
      "Epoch 114/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 272554.1562 - mae: 419.4933 - val_loss: 320536.1250 - val_mae: 457.0612\n",
      "Epoch 115/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 286805.6562 - mae: 432.7018 - val_loss: 317318.4688 - val_mae: 454.5022\n",
      "Epoch 116/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 264980.2812 - mae: 403.0345 - val_loss: 314060.9375 - val_mae: 451.8811\n",
      "Epoch 117/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 255997.2344 - mae: 403.9655 - val_loss: 310920.6562 - val_mae: 449.3337\n",
      "Epoch 118/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 242228.4062 - mae: 387.6405 - val_loss: 307703.8438 - val_mae: 446.7115\n",
      "Epoch 119/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 249919.8594 - mae: 395.3018 - val_loss: 304596.2188 - val_mae: 444.1403\n",
      "Epoch 120/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 270976.4375 - mae: 422.0186 - val_loss: 301397.0000 - val_mae: 441.5227\n",
      "Epoch 121/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 263920.2188 - mae: 405.6660 - val_loss: 298271.3750 - val_mae: 438.9485\n",
      "Epoch 122/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 261127.3281 - mae: 401.4186 - val_loss: 295226.5938 - val_mae: 436.3746\n",
      "Epoch 123/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 264793.1875 - mae: 407.1484 - val_loss: 292123.3438 - val_mae: 433.7642\n",
      "Epoch 124/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 248478.6875 - mae: 393.7990 - val_loss: 289106.2500 - val_mae: 431.1983\n",
      "Epoch 125/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 242676.9844 - mae: 390.7277 - val_loss: 285814.9688 - val_mae: 428.4353\n",
      "Epoch 126/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 234004.1875 - mae: 376.4606 - val_loss: 282550.2188 - val_mae: 425.6434\n",
      "Epoch 127/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 271303.2500 - mae: 411.3952 - val_loss: 279384.4062 - val_mae: 422.9411\n",
      "Epoch 128/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 266307.4688 - mae: 406.2657 - val_loss: 276279.5625 - val_mae: 420.2563\n",
      "Epoch 129/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 254305.6719 - mae: 398.4204 - val_loss: 273249.7188 - val_mae: 417.6057\n",
      "Epoch 130/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 228657.1094 - mae: 381.1436 - val_loss: 270205.0312 - val_mae: 414.9117\n",
      "Epoch 131/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 231940.8438 - mae: 376.7974 - val_loss: 267195.8750 - val_mae: 412.1976\n",
      "Epoch 132/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 226177.1406 - mae: 369.0447 - val_loss: 264110.0312 - val_mae: 409.4384\n",
      "Epoch 133/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 235649.7344 - mae: 384.2847 - val_loss: 261014.7969 - val_mae: 406.6401\n",
      "Epoch 134/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 229879.2500 - mae: 379.7104 - val_loss: 258130.1562 - val_mae: 404.0422\n",
      "Epoch 135/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 241951.8438 - mae: 381.6609 - val_loss: 255293.3594 - val_mae: 401.4687\n",
      "Epoch 136/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 243041.7031 - mae: 375.4784 - val_loss: 252462.4062 - val_mae: 398.8785\n",
      "Epoch 137/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 217755.9219 - mae: 365.0471 - val_loss: 249436.0625 - val_mae: 396.0695\n",
      "Epoch 138/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 199455.1719 - mae: 344.5072 - val_loss: 246587.0625 - val_mae: 393.4112\n",
      "Epoch 139/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 224544.5938 - mae: 375.0483 - val_loss: 243601.9062 - val_mae: 390.6410\n",
      "Epoch 140/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 232984.4531 - mae: 362.4044 - val_loss: 240767.5000 - val_mae: 387.9767\n",
      "Epoch 141/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 209662.0469 - mae: 358.8911 - val_loss: 238063.0781 - val_mae: 385.4191\n",
      "Epoch 142/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 215169.8906 - mae: 355.0996 - val_loss: 235357.4375 - val_mae: 382.8354\n",
      "Epoch 143/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 206498.2344 - mae: 347.0774 - val_loss: 232729.0781 - val_mae: 380.3012\n",
      "Epoch 144/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 217446.0312 - mae: 351.3756 - val_loss: 230278.2969 - val_mae: 377.9087\n",
      "Epoch 145/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 218280.0000 - mae: 354.2235 - val_loss: 227708.1406 - val_mae: 375.4120\n",
      "Epoch 146/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 195790.3438 - mae: 342.8404 - val_loss: 224959.0938 - val_mae: 372.7248\n",
      "Epoch 147/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 206049.3906 - mae: 350.1487 - val_loss: 222199.9844 - val_mae: 370.0162\n",
      "Epoch 148/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 206865.5156 - mae: 352.4691 - val_loss: 219594.6875 - val_mae: 367.4613\n",
      "Epoch 149/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 196485.4844 - mae: 335.8115 - val_loss: 216975.7344 - val_mae: 364.8715\n",
      "Epoch 150/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 198207.9062 - mae: 332.1493 - val_loss: 214349.8281 - val_mae: 362.2705\n",
      "Epoch 151/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 192788.0312 - mae: 331.4635 - val_loss: 211784.7656 - val_mae: 359.7254\n",
      "Epoch 152/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 187495.8281 - mae: 324.7534 - val_loss: 209159.7969 - val_mae: 357.0970\n",
      "Epoch 153/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 196653.5781 - mae: 336.4070 - val_loss: 206556.5469 - val_mae: 354.4583\n",
      "Epoch 154/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 195831.7500 - mae: 325.6285 - val_loss: 204029.3438 - val_mae: 351.8621\n",
      "Epoch 155/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 193225.6719 - mae: 329.4844 - val_loss: 201662.2812 - val_mae: 349.4314\n",
      "Epoch 156/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 190689.9219 - mae: 330.4463 - val_loss: 199230.3438 - val_mae: 346.9415\n",
      "Epoch 157/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 200621.9219 - mae: 328.6131 - val_loss: 196821.2812 - val_mae: 344.4913\n",
      "Epoch 158/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 207587.5312 - mae: 338.7188 - val_loss: 194500.0469 - val_mae: 342.1083\n",
      "Epoch 159/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 180322.9062 - mae: 324.0097 - val_loss: 192178.6250 - val_mae: 339.7212\n",
      "Epoch 160/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 185181.2500 - mae: 320.5951 - val_loss: 189953.6250 - val_mae: 337.3900\n",
      "Epoch 161/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 168774.7188 - mae: 313.8003 - val_loss: 187618.0781 - val_mae: 335.0147\n",
      "Epoch 162/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 162788.5000 - mae: 301.2903 - val_loss: 185314.4375 - val_mae: 332.6212\n",
      "Epoch 163/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 190233.3906 - mae: 326.7449 - val_loss: 183096.6250 - val_mae: 330.3269\n",
      "Epoch 164/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 211298.2188 - mae: 335.0712 - val_loss: 181040.1875 - val_mae: 328.1987\n",
      "Epoch 165/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 167040.1562 - mae: 310.4948 - val_loss: 179134.8906 - val_mae: 326.3007\n",
      "Epoch 166/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 164966.9062 - mae: 307.9773 - val_loss: 176923.1094 - val_mae: 324.0130\n",
      "Epoch 167/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 181434.6250 - mae: 317.2076 - val_loss: 174675.3750 - val_mae: 321.6723\n",
      "Epoch 168/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 187518.5938 - mae: 325.0382 - val_loss: 172818.2500 - val_mae: 319.7130\n",
      "Epoch 169/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 167325.7031 - mae: 306.9495 - val_loss: 170832.1094 - val_mae: 317.6582\n",
      "Epoch 170/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 176229.6562 - mae: 315.1521 - val_loss: 168692.3906 - val_mae: 315.3890\n",
      "Epoch 171/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 177053.1719 - mae: 310.0554 - val_loss: 166719.2188 - val_mae: 313.2974\n",
      "Epoch 172/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 185109.7188 - mae: 309.3819 - val_loss: 164869.5469 - val_mae: 311.3396\n",
      "Epoch 173/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 168289.1250 - mae: 306.8794 - val_loss: 162997.6250 - val_mae: 309.3479\n",
      "Epoch 174/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 138892.2812 - mae: 281.7744 - val_loss: 161062.4688 - val_mae: 307.3073\n",
      "Epoch 175/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 185779.6094 - mae: 317.0429 - val_loss: 159170.9062 - val_mae: 305.3143\n",
      "Epoch 176/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 188263.7812 - mae: 323.0728 - val_loss: 157385.7188 - val_mae: 303.4358\n",
      "Epoch 177/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 169373.0781 - mae: 307.4614 - val_loss: 155659.6250 - val_mae: 301.6081\n",
      "Epoch 178/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 167885.4375 - mae: 306.9866 - val_loss: 153945.8281 - val_mae: 299.7959\n",
      "Epoch 179/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 143350.5000 - mae: 287.2192 - val_loss: 152116.7188 - val_mae: 297.8349\n",
      "Epoch 180/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 171097.1094 - mae: 308.1766 - val_loss: 150289.7969 - val_mae: 295.8794\n",
      "Epoch 181/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 177350.8438 - mae: 305.4246 - val_loss: 148639.4219 - val_mae: 294.0912\n",
      "Epoch 182/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 164062.4844 - mae: 290.2198 - val_loss: 147078.2344 - val_mae: 292.3531\n",
      "Epoch 183/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 151170.5312 - mae: 286.0217 - val_loss: 145449.0312 - val_mae: 290.5363\n",
      "Epoch 184/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 154322.0469 - mae: 294.0415 - val_loss: 143782.5469 - val_mae: 288.6943\n",
      "Epoch 185/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 174122.8281 - mae: 307.1355 - val_loss: 142378.2188 - val_mae: 287.1091\n",
      "Epoch 186/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 147071.9844 - mae: 285.3755 - val_loss: 140859.2031 - val_mae: 285.4003\n",
      "Epoch 187/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 149242.0625 - mae: 274.3329 - val_loss: 139387.5938 - val_mae: 283.7564\n",
      "Epoch 188/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 142778.5938 - mae: 279.9010 - val_loss: 137887.3594 - val_mae: 282.0635\n",
      "Epoch 189/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 169744.2031 - mae: 294.1451 - val_loss: 136587.5000 - val_mae: 280.5869\n",
      "Epoch 190/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 160694.0469 - mae: 289.9127 - val_loss: 135372.0156 - val_mae: 279.1913\n",
      "Epoch 191/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 175438.9062 - mae: 300.9176 - val_loss: 133976.5312 - val_mae: 277.5587\n",
      "Epoch 192/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 147183.9531 - mae: 282.6090 - val_loss: 132562.8281 - val_mae: 275.8938\n",
      "Epoch 193/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 141987.3750 - mae: 275.7450 - val_loss: 131229.8594 - val_mae: 274.3260\n",
      "Epoch 194/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 161527.2188 - mae: 292.2607 - val_loss: 129893.4453 - val_mae: 272.7849\n",
      "Epoch 195/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 140662.3438 - mae: 273.6473 - val_loss: 128591.6172 - val_mae: 271.2365\n",
      "Epoch 196/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 147974.1719 - mae: 284.2479 - val_loss: 127482.6797 - val_mae: 269.9114\n",
      "Epoch 197/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 165923.6562 - mae: 293.3642 - val_loss: 126400.8438 - val_mae: 268.6184\n",
      "Epoch 198/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 132094.2344 - mae: 268.9179 - val_loss: 125241.1406 - val_mae: 267.2198\n",
      "Epoch 199/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 155922.5625 - mae: 283.0967 - val_loss: 124116.8125 - val_mae: 265.8649\n",
      "Epoch 200/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 164855.6875 - mae: 287.2661 - val_loss: 122977.9766 - val_mae: 264.4680\n",
      "Epoch 201/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 128890.9219 - mae: 259.5611 - val_loss: 121875.4688 - val_mae: 263.1150\n",
      "Epoch 202/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 150937.5000 - mae: 281.3511 - val_loss: 120853.9219 - val_mae: 261.8377\n",
      "Epoch 203/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 174373.8281 - mae: 296.8548 - val_loss: 119875.8047 - val_mae: 260.6317\n",
      "Epoch 204/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 137613.7344 - mae: 269.3146 - val_loss: 118857.9375 - val_mae: 259.3652\n",
      "Epoch 205/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 157789.1250 - mae: 292.3526 - val_loss: 117793.9766 - val_mae: 258.0348\n",
      "Epoch 206/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 144334.5000 - mae: 269.0199 - val_loss: 116982.7109 - val_mae: 257.0241\n",
      "Epoch 207/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 141504.7969 - mae: 262.4800 - val_loss: 116028.2656 - val_mae: 255.8206\n",
      "Epoch 208/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 140745.1875 - mae: 267.7977 - val_loss: 115049.0703 - val_mae: 254.5720\n",
      "Epoch 209/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 167846.5156 - mae: 300.2517 - val_loss: 114088.9297 - val_mae: 253.3248\n",
      "Epoch 210/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 153520.9688 - mae: 278.2990 - val_loss: 113156.0078 - val_mae: 252.1267\n",
      "Epoch 211/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 127245.5156 - mae: 259.6115 - val_loss: 112244.4375 - val_mae: 250.9595\n",
      "Epoch 212/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 193544.8750 - mae: 308.8268 - val_loss: 111594.3984 - val_mae: 250.1303\n",
      "Epoch 213/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 138506.3906 - mae: 270.5764 - val_loss: 110816.5859 - val_mae: 249.1149\n",
      "Epoch 214/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 132432.2500 - mae: 254.1343 - val_loss: 110017.6172 - val_mae: 248.0567\n",
      "Epoch 215/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 164272.7188 - mae: 293.0301 - val_loss: 109187.7969 - val_mae: 246.9659\n",
      "Epoch 216/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 145030.3281 - mae: 272.8054 - val_loss: 108434.7656 - val_mae: 245.9880\n",
      "Epoch 217/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 136840.3750 - mae: 264.9665 - val_loss: 107593.4375 - val_mae: 244.8662\n",
      "Epoch 218/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 140329.2969 - mae: 264.5682 - val_loss: 106736.5859 - val_mae: 243.7690\n",
      "Epoch 219/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 119590.6172 - mae: 249.0353 - val_loss: 106063.1719 - val_mae: 242.8969\n",
      "Epoch 220/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 155802.3438 - mae: 279.2705 - val_loss: 105444.9688 - val_mae: 242.0643\n",
      "Epoch 221/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 138201.1094 - mae: 266.4161 - val_loss: 104696.0547 - val_mae: 241.0458\n",
      "Epoch 222/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 148056.5625 - mae: 272.0497 - val_loss: 103980.3203 - val_mae: 240.0641\n",
      "Epoch 223/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 119350.2812 - mae: 250.6774 - val_loss: 103214.3828 - val_mae: 239.0461\n",
      "Epoch 224/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 143838.7188 - mae: 265.4467 - val_loss: 102505.6562 - val_mae: 238.1414\n",
      "Epoch 225/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 127271.0156 - mae: 265.1317 - val_loss: 101843.8906 - val_mae: 237.2869\n",
      "Epoch 226/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 119090.6641 - mae: 239.4298 - val_loss: 101192.5781 - val_mae: 236.4548\n",
      "Epoch 227/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 133687.3438 - mae: 260.5284 - val_loss: 100612.1016 - val_mae: 235.6999\n",
      "Epoch 228/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 145644.0000 - mae: 256.6350 - val_loss: 100061.7188 - val_mae: 234.9618\n",
      "Epoch 229/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 139705.5156 - mae: 279.2047 - val_loss: 99605.8281 - val_mae: 234.3607\n",
      "Epoch 230/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 148360.6562 - mae: 268.5558 - val_loss: 99155.5547 - val_mae: 233.7801\n",
      "Epoch 231/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 133300.2969 - mae: 259.2956 - val_loss: 98603.1641 - val_mae: 233.0306\n",
      "Epoch 232/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 150259.6250 - mae: 270.2733 - val_loss: 98104.7578 - val_mae: 232.3610\n",
      "Epoch 233/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 135810.9844 - mae: 254.3074 - val_loss: 97629.5312 - val_mae: 231.7225\n",
      "Epoch 234/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 146494.7031 - mae: 272.1915 - val_loss: 97285.0078 - val_mae: 231.2550\n",
      "Epoch 235/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 158388.0000 - mae: 281.1494 - val_loss: 96954.5547 - val_mae: 230.8110\n",
      "Epoch 236/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 164120.9844 - mae: 284.3692 - val_loss: 96632.4453 - val_mae: 230.3918\n",
      "Epoch 237/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 135597.1250 - mae: 255.4456 - val_loss: 96277.6016 - val_mae: 229.8963\n",
      "Epoch 238/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 117252.4219 - mae: 244.0834 - val_loss: 95960.2500 - val_mae: 229.4480\n",
      "Epoch 239/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 167271.9844 - mae: 284.0507 - val_loss: 95681.6484 - val_mae: 229.0680\n",
      "Epoch 240/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 135820.2188 - mae: 265.4373 - val_loss: 95325.3594 - val_mae: 228.5708\n",
      "Epoch 241/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 135209.5781 - mae: 257.5157 - val_loss: 94896.1797 - val_mae: 227.9853\n",
      "Epoch 242/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 150691.9688 - mae: 275.8864 - val_loss: 94622.2188 - val_mae: 227.6159\n",
      "Epoch 243/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 141384.2031 - mae: 262.1523 - val_loss: 94239.7891 - val_mae: 227.0789\n",
      "Epoch 244/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 162044.7656 - mae: 268.4257 - val_loss: 93859.6797 - val_mae: 226.5771\n",
      "Epoch 245/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 157676.5625 - mae: 273.5571 - val_loss: 93477.0938 - val_mae: 226.0232\n",
      "Epoch 246/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 131759.2969 - mae: 258.2896 - val_loss: 92974.6016 - val_mae: 225.3087\n",
      "Epoch 247/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 141994.2500 - mae: 257.5738 - val_loss: 92613.9062 - val_mae: 224.8389\n",
      "Epoch 248/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 140052.7500 - mae: 271.7219 - val_loss: 92340.2109 - val_mae: 224.4757\n",
      "Epoch 249/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 135744.2188 - mae: 254.3826 - val_loss: 91958.2188 - val_mae: 223.9250\n",
      "Epoch 250/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 124537.5859 - mae: 252.1325 - val_loss: 91553.5156 - val_mae: 223.3329\n",
      "Epoch 251/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 159380.0625 - mae: 283.1197 - val_loss: 91159.0000 - val_mae: 222.7680\n",
      "Epoch 252/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 125225.5391 - mae: 247.2388 - val_loss: 90891.7578 - val_mae: 222.3473\n",
      "Epoch 253/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 159791.0156 - mae: 274.7376 - val_loss: 90676.9453 - val_mae: 222.0449\n",
      "Epoch 254/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 126796.2188 - mae: 255.4339 - val_loss: 90324.3125 - val_mae: 221.5268\n",
      "Epoch 255/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 147456.4375 - mae: 268.9728 - val_loss: 90134.4062 - val_mae: 221.2792\n",
      "Epoch 256/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 133937.4062 - mae: 258.8866 - val_loss: 89743.2734 - val_mae: 220.7105\n",
      "Epoch 257/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 136557.3281 - mae: 260.3383 - val_loss: 89365.0781 - val_mae: 220.1449\n",
      "Epoch 258/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 148426.1250 - mae: 280.1534 - val_loss: 89052.7266 - val_mae: 219.6845\n",
      "Epoch 259/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 139015.0469 - mae: 270.8380 - val_loss: 88783.8359 - val_mae: 219.2941\n",
      "Epoch 260/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 114675.1562 - mae: 239.6453 - val_loss: 88450.8359 - val_mae: 218.8033\n",
      "Epoch 261/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 123176.6719 - mae: 239.9228 - val_loss: 88306.4453 - val_mae: 218.6220\n",
      "Epoch 262/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 128691.8359 - mae: 253.8324 - val_loss: 88001.2812 - val_mae: 218.1546\n",
      "Epoch 263/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 139360.7969 - mae: 256.9725 - val_loss: 87832.6172 - val_mae: 217.9091\n",
      "Epoch 264/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 137842.1250 - mae: 259.8047 - val_loss: 87801.6172 - val_mae: 217.8688\n",
      "Epoch 265/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 117245.7812 - mae: 239.5849 - val_loss: 87767.0000 - val_mae: 217.8291\n",
      "Epoch 266/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 113182.7109 - mae: 245.2501 - val_loss: 87515.7891 - val_mae: 217.4556\n",
      "Epoch 267/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 140403.2500 - mae: 258.2067 - val_loss: 87280.8203 - val_mae: 217.1210\n",
      "Epoch 268/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 150998.4375 - mae: 271.1681 - val_loss: 86991.5859 - val_mae: 216.6886\n",
      "Epoch 269/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 139688.0156 - mae: 263.3895 - val_loss: 86795.1641 - val_mae: 216.4174\n",
      "Epoch 270/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 132428.6094 - mae: 254.6014 - val_loss: 86625.5234 - val_mae: 216.1355\n",
      "Epoch 271/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 136928.4062 - mae: 253.2483 - val_loss: 86319.9609 - val_mae: 215.6696\n",
      "Epoch 272/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 145137.6719 - mae: 271.5451 - val_loss: 86338.7734 - val_mae: 215.7078\n",
      "Epoch 273/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 129083.3906 - mae: 251.0422 - val_loss: 86257.7422 - val_mae: 215.6137\n",
      "Epoch 274/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 135552.6406 - mae: 255.6497 - val_loss: 86066.8828 - val_mae: 215.3701\n",
      "Epoch 275/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 149674.8281 - mae: 272.1912 - val_loss: 86056.1953 - val_mae: 215.4222\n",
      "Epoch 276/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 121442.4766 - mae: 249.4519 - val_loss: 85797.6328 - val_mae: 215.0371\n",
      "Epoch 277/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 149880.6562 - mae: 269.9378 - val_loss: 85512.5469 - val_mae: 214.6227\n",
      "Epoch 278/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 133620.5000 - mae: 252.9394 - val_loss: 85306.6172 - val_mae: 214.3436\n",
      "Epoch 279/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 125061.4766 - mae: 258.8254 - val_loss: 85053.6562 - val_mae: 213.9685\n",
      "Epoch 280/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 112593.2812 - mae: 234.6940 - val_loss: 84895.8203 - val_mae: 213.7823\n",
      "Epoch 281/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 136892.9375 - mae: 258.7467 - val_loss: 84631.7344 - val_mae: 213.3790\n",
      "Epoch 282/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 142313.9531 - mae: 256.3828 - val_loss: 84478.7188 - val_mae: 213.1480\n",
      "Epoch 283/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 152254.4219 - mae: 276.4609 - val_loss: 84249.4297 - val_mae: 212.8085\n",
      "Epoch 284/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 138965.6094 - mae: 249.6658 - val_loss: 84122.1172 - val_mae: 212.6679\n",
      "Epoch 285/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 121860.9219 - mae: 232.4425 - val_loss: 83966.6328 - val_mae: 212.4505\n",
      "Epoch 286/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 122820.0391 - mae: 244.5611 - val_loss: 83560.1016 - val_mae: 211.7908\n",
      "Epoch 287/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 124615.3281 - mae: 247.1534 - val_loss: 83378.1719 - val_mae: 211.5143\n",
      "Epoch 288/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 155195.6562 - mae: 268.9241 - val_loss: 83169.1484 - val_mae: 211.2006\n",
      "Epoch 289/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 154894.5469 - mae: 268.5990 - val_loss: 83163.3438 - val_mae: 211.2146\n",
      "Epoch 290/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 112725.2578 - mae: 236.3719 - val_loss: 83085.2031 - val_mae: 211.1077\n",
      "Epoch 291/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 155436.0625 - mae: 268.3151 - val_loss: 83159.6875 - val_mae: 211.2681\n",
      "Epoch 292/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 124805.1953 - mae: 250.5790 - val_loss: 83032.7109 - val_mae: 211.0608\n",
      "Epoch 293/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 159835.9219 - mae: 273.2827 - val_loss: 82960.0156 - val_mae: 210.9419\n",
      "Epoch 294/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 146254.3906 - mae: 263.3534 - val_loss: 82759.9922 - val_mae: 210.6160\n",
      "Epoch 295/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 158867.5938 - mae: 271.4637 - val_loss: 82760.4922 - val_mae: 210.6434\n",
      "Epoch 296/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 138239.3594 - mae: 266.9489 - val_loss: 82672.7031 - val_mae: 210.5340\n",
      "Epoch 297/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 105802.8203 - mae: 231.6273 - val_loss: 82483.0781 - val_mae: 210.2540\n",
      "Epoch 298/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 137205.5156 - mae: 259.9735 - val_loss: 82106.9531 - val_mae: 209.6361\n",
      "Epoch 299/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 148078.8125 - mae: 272.8240 - val_loss: 81909.2734 - val_mae: 209.3278\n",
      "Epoch 300/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 142509.4688 - mae: 266.7684 - val_loss: 81753.6094 - val_mae: 209.1306\n",
      "Epoch 301/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 134434.6094 - mae: 253.4672 - val_loss: 81663.3672 - val_mae: 209.0388\n",
      "Epoch 302/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 128290.6094 - mae: 253.4016 - val_loss: 81390.0781 - val_mae: 208.6095\n",
      "Epoch 303/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 140999.4219 - mae: 257.9500 - val_loss: 81255.7969 - val_mae: 208.3991\n",
      "Epoch 304/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 141179.7500 - mae: 258.4854 - val_loss: 81204.7266 - val_mae: 208.3331\n",
      "Epoch 305/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 124325.4375 - mae: 247.7359 - val_loss: 81065.4609 - val_mae: 208.0958\n",
      "Epoch 306/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 144164.6562 - mae: 257.1702 - val_loss: 81031.4141 - val_mae: 208.0616\n",
      "Epoch 307/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 143110.9844 - mae: 263.0050 - val_loss: 81080.5625 - val_mae: 208.2131\n",
      "Epoch 308/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 136202.4688 - mae: 251.9672 - val_loss: 80965.0859 - val_mae: 208.0498\n",
      "Epoch 309/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 121580.7578 - mae: 237.2417 - val_loss: 80910.6953 - val_mae: 207.9384\n",
      "Epoch 310/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 140167.2500 - mae: 256.7943 - val_loss: 81012.8281 - val_mae: 208.1259\n",
      "Epoch 311/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 134122.1875 - mae: 260.0695 - val_loss: 81164.0859 - val_mae: 208.4628\n",
      "Epoch 312/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 129539.3516 - mae: 252.4895 - val_loss: 80970.3438 - val_mae: 208.2030\n",
      "Epoch 313/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 151641.4375 - mae: 270.4706 - val_loss: 80862.9844 - val_mae: 208.0389\n",
      "Epoch 314/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 141366.6250 - mae: 260.9396 - val_loss: 80945.3125 - val_mae: 208.2233\n",
      "Epoch 315/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 105034.4688 - mae: 227.0574 - val_loss: 80932.2656 - val_mae: 208.2544\n",
      "Epoch 316/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 124089.8594 - mae: 245.1422 - val_loss: 80931.8984 - val_mae: 208.2663\n",
      "Epoch 317/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 142558.9844 - mae: 263.2606 - val_loss: 80944.1016 - val_mae: 208.2884\n",
      "Epoch 318/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 163712.9375 - mae: 273.4846 - val_loss: 80959.9766 - val_mae: 208.2877\n",
      "Epoch 319/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 125308.8672 - mae: 250.7726 - val_loss: 80717.9766 - val_mae: 207.8515\n",
      "Epoch 320/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 129713.8828 - mae: 242.8387 - val_loss: 80568.7578 - val_mae: 207.6279\n",
      "Epoch 321/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 128771.1719 - mae: 246.1642 - val_loss: 80571.6562 - val_mae: 207.6901\n",
      "Epoch 322/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 149376.1094 - mae: 270.9854 - val_loss: 80536.1016 - val_mae: 207.6831\n",
      "Epoch 323/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 133599.6094 - mae: 256.0115 - val_loss: 80393.5703 - val_mae: 207.4952\n",
      "Epoch 324/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 144268.6562 - mae: 261.1007 - val_loss: 80377.0078 - val_mae: 207.5266\n",
      "Epoch 325/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 148028.7500 - mae: 265.3268 - val_loss: 80365.5000 - val_mae: 207.5473\n",
      "Epoch 326/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 141904.5469 - mae: 243.2105 - val_loss: 80397.4844 - val_mae: 207.6354\n",
      "Epoch 327/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 128481.6875 - mae: 243.7438 - val_loss: 80251.9219 - val_mae: 207.4122\n",
      "Epoch 328/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 115413.5156 - mae: 238.7075 - val_loss: 80033.9609 - val_mae: 207.0695\n",
      "Epoch 329/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 125392.4219 - mae: 238.9705 - val_loss: 79789.9688 - val_mae: 206.6241\n",
      "Epoch 330/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 108957.2031 - mae: 221.4731 - val_loss: 79515.7656 - val_mae: 206.1460\n",
      "Epoch 331/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 129708.2031 - mae: 249.6777 - val_loss: 79328.6562 - val_mae: 205.8416\n",
      "Epoch 332/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 141913.5000 - mae: 264.8163 - val_loss: 79174.4141 - val_mae: 205.5590\n",
      "Epoch 333/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 114231.5938 - mae: 234.7523 - val_loss: 79007.0000 - val_mae: 205.3339\n",
      "Epoch 334/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 134202.4531 - mae: 255.7778 - val_loss: 78909.1328 - val_mae: 205.2250\n",
      "Epoch 335/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 122554.4297 - mae: 240.0882 - val_loss: 78770.2969 - val_mae: 205.0110\n",
      "Epoch 336/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 120927.7656 - mae: 252.6415 - val_loss: 78694.1719 - val_mae: 204.8701\n",
      "Epoch 337/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 148355.2344 - mae: 260.0238 - val_loss: 78748.8594 - val_mae: 204.9751\n",
      "Epoch 338/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 146895.8125 - mae: 266.7545 - val_loss: 78447.7578 - val_mae: 204.3805\n",
      "Epoch 339/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 141277.3281 - mae: 255.5279 - val_loss: 78395.3047 - val_mae: 204.2440\n",
      "Epoch 340/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 142234.5312 - mae: 257.9774 - val_loss: 78516.7656 - val_mae: 204.4873\n",
      "Epoch 341/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 147122.6406 - mae: 267.2633 - val_loss: 78525.8906 - val_mae: 204.4865\n",
      "Epoch 342/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 140536.8594 - mae: 256.3246 - val_loss: 78400.5938 - val_mae: 204.2774\n",
      "Epoch 343/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 121600.2109 - mae: 241.8248 - val_loss: 78080.5078 - val_mae: 203.7355\n",
      "Epoch 344/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 152118.1719 - mae: 270.4931 - val_loss: 77868.0156 - val_mae: 203.3518\n",
      "Epoch 345/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 125915.1797 - mae: 246.9666 - val_loss: 77734.4297 - val_mae: 203.1186\n",
      "Epoch 346/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 150022.8438 - mae: 267.8898 - val_loss: 77771.2969 - val_mae: 203.2211\n",
      "Epoch 347/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 141686.7344 - mae: 253.9106 - val_loss: 77612.2812 - val_mae: 202.9949\n",
      "Epoch 348/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 149860.0625 - mae: 257.9193 - val_loss: 77428.8359 - val_mae: 202.7134\n",
      "Epoch 349/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 122358.3125 - mae: 239.1271 - val_loss: 77209.3906 - val_mae: 202.3006\n",
      "Epoch 350/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 118081.4062 - mae: 238.1004 - val_loss: 77231.1406 - val_mae: 202.3638\n",
      "Epoch 351/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 150424.0469 - mae: 266.9363 - val_loss: 77340.7891 - val_mae: 202.6264\n",
      "Epoch 352/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 140545.5625 - mae: 257.2073 - val_loss: 77235.2031 - val_mae: 202.4492\n",
      "Epoch 353/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 131594.0938 - mae: 243.8860 - val_loss: 77290.4844 - val_mae: 202.6113\n",
      "Epoch 354/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 133780.9531 - mae: 250.1407 - val_loss: 77340.8594 - val_mae: 202.8270\n",
      "Epoch 355/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 139397.3281 - mae: 253.4423 - val_loss: 77192.4609 - val_mae: 202.6279\n",
      "Epoch 356/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 117856.0312 - mae: 242.1347 - val_loss: 77097.9531 - val_mae: 202.4520\n",
      "Epoch 357/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 145261.9219 - mae: 260.8701 - val_loss: 77094.7734 - val_mae: 202.5117\n",
      "Epoch 358/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 122808.6250 - mae: 242.2870 - val_loss: 77194.2031 - val_mae: 202.7121\n",
      "Epoch 359/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 126949.7578 - mae: 249.8144 - val_loss: 77159.9453 - val_mae: 202.6543\n",
      "Epoch 360/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 129405.2031 - mae: 248.4204 - val_loss: 77160.4375 - val_mae: 202.6667\n",
      "Epoch 361/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 141577.3438 - mae: 258.0792 - val_loss: 77095.2031 - val_mae: 202.5229\n",
      "Epoch 362/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 139530.6719 - mae: 258.4524 - val_loss: 76991.7734 - val_mae: 202.2971\n",
      "Epoch 363/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 148209.7500 - mae: 252.3923 - val_loss: 76872.5156 - val_mae: 202.0820\n",
      "Epoch 364/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 141169.1094 - mae: 249.9671 - val_loss: 76870.7969 - val_mae: 202.1336\n",
      "Epoch 365/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 124781.7422 - mae: 241.4936 - val_loss: 77020.4766 - val_mae: 202.4762\n",
      "Epoch 366/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 148815.6875 - mae: 264.6589 - val_loss: 77072.5625 - val_mae: 202.5394\n",
      "Epoch 367/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 133583.8281 - mae: 257.8404 - val_loss: 77152.3125 - val_mae: 202.6838\n",
      "Epoch 368/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 132224.3594 - mae: 240.8849 - val_loss: 77180.9297 - val_mae: 202.7835\n",
      "Epoch 369/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 144341.5156 - mae: 265.3013 - val_loss: 77261.4219 - val_mae: 203.0302\n",
      "Epoch 370/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 133673.4531 - mae: 247.6926 - val_loss: 77328.0781 - val_mae: 203.2417\n",
      "Epoch 371/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 123300.6562 - mae: 236.4067 - val_loss: 77378.0469 - val_mae: 203.4017\n",
      "Epoch 372/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 120223.3203 - mae: 237.3373 - val_loss: 77455.5391 - val_mae: 203.5768\n",
      "Epoch 373/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 126439.0078 - mae: 236.8664 - val_loss: 77624.1562 - val_mae: 203.9168\n",
      "Epoch 374/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 130634.0156 - mae: 246.5573 - val_loss: 77423.3438 - val_mae: 203.5583\n",
      "Epoch 375/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 113676.1797 - mae: 225.8266 - val_loss: 77236.8594 - val_mae: 203.2021\n",
      "Epoch 376/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 124403.6172 - mae: 239.5864 - val_loss: 77234.9844 - val_mae: 203.2397\n",
      "Epoch 377/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 113543.9453 - mae: 230.0244 - val_loss: 77190.5859 - val_mae: 203.2104\n",
      "Epoch 378/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 135293.5312 - mae: 250.4485 - val_loss: 77009.5078 - val_mae: 202.8757\n",
      "Epoch 379/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 132956.3594 - mae: 251.8999 - val_loss: 76908.7422 - val_mae: 202.7130\n",
      "Epoch 380/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 129811.7344 - mae: 248.5428 - val_loss: 76722.7109 - val_mae: 202.3533\n",
      "Epoch 381/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 148473.6562 - mae: 257.9125 - val_loss: 76841.0234 - val_mae: 202.6794\n",
      "Epoch 382/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 150388.6406 - mae: 256.1345 - val_loss: 77066.4453 - val_mae: 203.1906\n",
      "Epoch 383/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 127098.5469 - mae: 244.6655 - val_loss: 76578.5078 - val_mae: 202.2225\n",
      "Epoch 384/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 150376.7500 - mae: 261.7271 - val_loss: 76399.2500 - val_mae: 201.8811\n",
      "Epoch 385/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 118198.9531 - mae: 241.2580 - val_loss: 76014.0234 - val_mae: 201.1150\n",
      "Epoch 386/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 114975.7656 - mae: 233.8801 - val_loss: 75736.2266 - val_mae: 200.5959\n",
      "Epoch 387/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 117076.1719 - mae: 234.4346 - val_loss: 75561.1797 - val_mae: 200.2546\n",
      "Epoch 388/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 126517.6094 - mae: 245.8211 - val_loss: 75391.3672 - val_mae: 199.9351\n",
      "Epoch 389/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 122978.5391 - mae: 243.3577 - val_loss: 75089.4844 - val_mae: 199.3524\n",
      "Epoch 390/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 125136.8047 - mae: 240.4977 - val_loss: 74852.3125 - val_mae: 198.9123\n",
      "Epoch 391/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 121276.0781 - mae: 231.6291 - val_loss: 74997.4297 - val_mae: 199.2588\n",
      "Epoch 392/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 122557.9297 - mae: 236.0200 - val_loss: 75014.5859 - val_mae: 199.2971\n",
      "Epoch 393/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 131998.8438 - mae: 253.4665 - val_loss: 74738.8984 - val_mae: 198.7921\n",
      "Epoch 394/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 150476.2500 - mae: 251.7120 - val_loss: 74724.4453 - val_mae: 198.8279\n",
      "Epoch 395/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 134545.2031 - mae: 248.9335 - val_loss: 74539.0625 - val_mae: 198.5247\n",
      "Epoch 396/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 139303.8438 - mae: 255.7871 - val_loss: 74627.1484 - val_mae: 198.7173\n",
      "Epoch 397/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 124287.9531 - mae: 245.1272 - val_loss: 74675.3750 - val_mae: 198.8662\n",
      "Epoch 398/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 109320.7891 - mae: 226.0320 - val_loss: 74507.6797 - val_mae: 198.5549\n",
      "Epoch 399/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 105810.3359 - mae: 222.7532 - val_loss: 74627.2422 - val_mae: 198.8607\n",
      "Epoch 400/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 136903.1562 - mae: 260.6341 - val_loss: 74584.9766 - val_mae: 198.7814\n",
      "Epoch 401/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 140772.7188 - mae: 252.0228 - val_loss: 74550.7266 - val_mae: 198.6795\n",
      "Epoch 402/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 134149.5312 - mae: 252.4660 - val_loss: 74772.9219 - val_mae: 199.2227\n",
      "Epoch 403/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 147834.2812 - mae: 248.6601 - val_loss: 74791.0625 - val_mae: 199.3283\n",
      "Epoch 404/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 158608.3594 - mae: 271.7768 - val_loss: 74575.5859 - val_mae: 198.9492\n",
      "Epoch 405/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 170171.3594 - mae: 276.1564 - val_loss: 74665.9141 - val_mae: 199.1304\n",
      "Epoch 406/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 148612.1875 - mae: 257.1461 - val_loss: 74648.5703 - val_mae: 199.1728\n",
      "Epoch 407/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 107610.6953 - mae: 219.4880 - val_loss: 74748.8438 - val_mae: 199.3883\n",
      "Epoch 408/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 120420.5781 - mae: 234.4555 - val_loss: 74803.4844 - val_mae: 199.4763\n",
      "Epoch 409/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 105018.7031 - mae: 219.6778 - val_loss: 74817.3594 - val_mae: 199.4918\n",
      "Epoch 410/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 142542.8906 - mae: 256.5359 - val_loss: 75005.9219 - val_mae: 199.9244\n",
      "Epoch 411/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 119938.0234 - mae: 227.8107 - val_loss: 74936.5078 - val_mae: 199.7972\n",
      "Epoch 412/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 121747.5312 - mae: 235.0652 - val_loss: 74976.6875 - val_mae: 199.8948\n",
      "Epoch 413/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 133620.2500 - mae: 254.8984 - val_loss: 74965.6406 - val_mae: 199.8102\n",
      "Epoch 414/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 104111.3984 - mae: 222.1680 - val_loss: 74681.2891 - val_mae: 199.1583\n",
      "Epoch 415/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 124439.8516 - mae: 237.6123 - val_loss: 74331.0156 - val_mae: 198.4684\n",
      "Epoch 416/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 141356.6719 - mae: 255.8621 - val_loss: 74217.2734 - val_mae: 198.2769\n",
      "Epoch 417/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 110001.4688 - mae: 225.5875 - val_loss: 74132.7969 - val_mae: 198.1618\n",
      "Epoch 418/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 137832.2188 - mae: 246.5686 - val_loss: 73993.5000 - val_mae: 197.9502\n",
      "Epoch 419/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 124035.3438 - mae: 236.1644 - val_loss: 74005.2734 - val_mae: 197.9941\n",
      "Epoch 420/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 121268.5859 - mae: 239.5511 - val_loss: 73812.0312 - val_mae: 197.5974\n",
      "Epoch 421/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 114909.8672 - mae: 230.6563 - val_loss: 73839.2031 - val_mae: 197.6778\n",
      "Epoch 422/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 139416.0312 - mae: 252.9084 - val_loss: 73621.6875 - val_mae: 197.2520\n",
      "Epoch 423/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 141486.5469 - mae: 255.4746 - val_loss: 73592.4375 - val_mae: 197.2265\n",
      "Epoch 424/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 120485.7109 - mae: 227.6615 - val_loss: 73457.3672 - val_mae: 196.9312\n",
      "Epoch 425/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 116248.7109 - mae: 224.9193 - val_loss: 73420.7578 - val_mae: 196.8883\n",
      "Epoch 426/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 139000.3594 - mae: 252.1770 - val_loss: 73565.0703 - val_mae: 197.2700\n",
      "Epoch 427/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 124079.5312 - mae: 237.2750 - val_loss: 73723.6094 - val_mae: 197.5967\n",
      "Epoch 428/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 98191.8125 - mae: 219.1387 - val_loss: 73685.8438 - val_mae: 197.5645\n",
      "Epoch 429/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 116249.0547 - mae: 231.7320 - val_loss: 73738.6562 - val_mae: 197.6407\n",
      "Epoch 430/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 111014.2188 - mae: 229.4983 - val_loss: 73760.4219 - val_mae: 197.7325\n",
      "Epoch 431/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 134359.6094 - mae: 243.6642 - val_loss: 73725.6094 - val_mae: 197.7008\n",
      "Epoch 432/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 128263.4219 - mae: 242.3053 - val_loss: 73848.7969 - val_mae: 197.9257\n",
      "Epoch 433/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 126960.9922 - mae: 243.2119 - val_loss: 73861.7812 - val_mae: 197.8883\n",
      "Epoch 434/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 95845.1875 - mae: 220.9178 - val_loss: 73899.4297 - val_mae: 197.9671\n",
      "Epoch 435/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 130598.1719 - mae: 236.2850 - val_loss: 74000.1250 - val_mae: 198.2243\n",
      "Epoch 436/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 87584.1719 - mae: 200.7175 - val_loss: 74083.8828 - val_mae: 198.4768\n",
      "Epoch 437/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 144987.5156 - mae: 253.7744 - val_loss: 73950.0312 - val_mae: 198.2591\n",
      "Epoch 438/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 111372.5078 - mae: 231.5105 - val_loss: 73709.8281 - val_mae: 197.7076\n",
      "Epoch 439/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 133338.1719 - mae: 246.4790 - val_loss: 73367.0703 - val_mae: 197.0167\n",
      "Epoch 440/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 120066.4453 - mae: 242.7649 - val_loss: 73376.7969 - val_mae: 197.1156\n",
      "Epoch 441/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 140741.8125 - mae: 256.6365 - val_loss: 73319.7109 - val_mae: 197.1325\n",
      "Epoch 442/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 113173.0938 - mae: 233.2663 - val_loss: 73450.2422 - val_mae: 197.5332\n",
      "Epoch 443/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 108751.7109 - mae: 221.6930 - val_loss: 73601.6172 - val_mae: 197.9731\n",
      "Epoch 444/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 121893.7422 - mae: 236.7346 - val_loss: 73962.5938 - val_mae: 198.9070\n",
      "Epoch 445/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 129203.1328 - mae: 243.1738 - val_loss: 73783.8281 - val_mae: 198.6412\n",
      "Epoch 446/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 115958.1562 - mae: 231.9593 - val_loss: 73685.5391 - val_mae: 198.4564\n",
      "Epoch 447/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 111077.3359 - mae: 227.1857 - val_loss: 73583.2734 - val_mae: 198.2853\n",
      "Epoch 448/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 122755.3047 - mae: 242.5609 - val_loss: 73311.0703 - val_mae: 197.7540\n",
      "Epoch 449/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 129990.0000 - mae: 239.7478 - val_loss: 73230.6484 - val_mae: 197.5647\n",
      "Epoch 450/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 135544.7812 - mae: 242.4048 - val_loss: 73103.9219 - val_mae: 197.2530\n",
      "Epoch 451/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 135308.0000 - mae: 241.6386 - val_loss: 72943.4375 - val_mae: 196.9136\n",
      "Epoch 452/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 124578.2344 - mae: 235.0346 - val_loss: 72766.9297 - val_mae: 196.5056\n",
      "Epoch 453/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 120473.1328 - mae: 237.4263 - val_loss: 72502.7188 - val_mae: 195.9233\n",
      "Epoch 454/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 121682.6406 - mae: 242.2482 - val_loss: 72303.3438 - val_mae: 195.4424\n",
      "Epoch 455/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 112782.0156 - mae: 229.0805 - val_loss: 72424.4922 - val_mae: 195.7496\n",
      "Epoch 456/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 123750.8516 - mae: 238.2788 - val_loss: 72392.7969 - val_mae: 195.7833\n",
      "Epoch 457/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 133984.3438 - mae: 243.4161 - val_loss: 72295.8281 - val_mae: 195.6785\n",
      "Epoch 458/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 110044.8047 - mae: 231.1883 - val_loss: 72309.0625 - val_mae: 195.7987\n",
      "Epoch 459/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 152599.5000 - mae: 251.9324 - val_loss: 72231.0469 - val_mae: 195.6188\n",
      "Epoch 460/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 149462.4844 - mae: 259.0720 - val_loss: 72224.0703 - val_mae: 195.5790\n",
      "Epoch 461/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 129542.8906 - mae: 236.0003 - val_loss: 72293.2656 - val_mae: 195.7071\n",
      "Epoch 462/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 129176.7578 - mae: 244.5260 - val_loss: 72305.4531 - val_mae: 195.7076\n",
      "Epoch 463/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 99243.7812 - mae: 220.4940 - val_loss: 72389.5391 - val_mae: 195.8753\n",
      "Epoch 464/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 112097.1562 - mae: 228.6695 - val_loss: 72447.9141 - val_mae: 195.9780\n",
      "Epoch 465/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 129897.8516 - mae: 238.7555 - val_loss: 72224.6016 - val_mae: 195.4054\n",
      "Epoch 466/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 132088.9844 - mae: 248.3866 - val_loss: 72245.6172 - val_mae: 195.4816\n",
      "Epoch 467/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 111511.4141 - mae: 232.0972 - val_loss: 72454.1016 - val_mae: 195.9830\n",
      "Epoch 468/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 113651.6562 - mae: 226.5741 - val_loss: 72526.5781 - val_mae: 196.1994\n",
      "Epoch 469/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 133982.7031 - mae: 238.5015 - val_loss: 72496.7578 - val_mae: 196.2330\n",
      "Epoch 470/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 123258.6719 - mae: 241.5872 - val_loss: 72574.5234 - val_mae: 196.5196\n",
      "Epoch 471/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 128869.3984 - mae: 235.8680 - val_loss: 72667.2109 - val_mae: 196.7834\n",
      "Epoch 472/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 115306.8516 - mae: 231.3067 - val_loss: 72444.5469 - val_mae: 196.2831\n",
      "Epoch 473/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 133772.3906 - mae: 247.7698 - val_loss: 72366.5312 - val_mae: 196.0822\n",
      "Epoch 474/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 125055.7891 - mae: 241.6668 - val_loss: 72241.9531 - val_mae: 195.7963\n",
      "Epoch 475/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 129465.9453 - mae: 245.3514 - val_loss: 72120.5938 - val_mae: 195.5150\n",
      "Epoch 476/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 135987.2969 - mae: 245.4334 - val_loss: 72073.6562 - val_mae: 195.4139\n",
      "Epoch 477/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 118583.7344 - mae: 231.5224 - val_loss: 72052.9922 - val_mae: 195.4520\n",
      "Epoch 478/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 147700.2812 - mae: 252.4877 - val_loss: 71852.9141 - val_mae: 195.0270\n",
      "Epoch 479/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 144036.3438 - mae: 250.1208 - val_loss: 71661.2812 - val_mae: 194.6266\n",
      "Epoch 480/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 116751.8984 - mae: 230.8616 - val_loss: 71701.4297 - val_mae: 194.6938\n",
      "Epoch 481/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 106076.8750 - mae: 220.9045 - val_loss: 71627.2266 - val_mae: 194.5607\n",
      "Epoch 482/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 121903.3438 - mae: 227.7266 - val_loss: 71805.1094 - val_mae: 195.0646\n",
      "Epoch 483/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 115659.4453 - mae: 236.3523 - val_loss: 71846.9766 - val_mae: 195.2189\n",
      "Epoch 484/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 137127.0938 - mae: 239.8349 - val_loss: 71940.0156 - val_mae: 195.3574\n",
      "Epoch 485/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 138467.5312 - mae: 244.8652 - val_loss: 71881.4141 - val_mae: 195.2595\n",
      "Epoch 486/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 132818.5000 - mae: 244.2368 - val_loss: 71787.3984 - val_mae: 195.0956\n",
      "Epoch 487/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 113299.7500 - mae: 230.1448 - val_loss: 71555.3984 - val_mae: 194.5991\n",
      "Epoch 488/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 119696.9141 - mae: 231.9447 - val_loss: 71534.3125 - val_mae: 194.5815\n",
      "Epoch 489/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 136318.9062 - mae: 248.6596 - val_loss: 71383.3125 - val_mae: 194.2417\n",
      "Epoch 490/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 122068.0000 - mae: 230.5445 - val_loss: 71540.3359 - val_mae: 194.5831\n",
      "Epoch 491/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 137809.4844 - mae: 252.4851 - val_loss: 71664.8594 - val_mae: 194.8768\n",
      "Epoch 492/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 124807.5391 - mae: 234.2796 - val_loss: 71665.9219 - val_mae: 194.8806\n",
      "Epoch 493/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 115788.4688 - mae: 232.8948 - val_loss: 71664.7969 - val_mae: 194.8705\n",
      "Epoch 494/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 126415.6172 - mae: 231.6234 - val_loss: 71557.5859 - val_mae: 194.7009\n",
      "Epoch 495/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 90511.5469 - mae: 198.7104 - val_loss: 71680.7266 - val_mae: 194.9914\n",
      "Epoch 496/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 118840.0781 - mae: 226.8277 - val_loss: 71602.7734 - val_mae: 194.7434\n",
      "Epoch 497/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 115637.3672 - mae: 227.2041 - val_loss: 71442.7891 - val_mae: 194.3497\n",
      "Epoch 498/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 137913.0156 - mae: 248.8440 - val_loss: 71334.1016 - val_mae: 194.1582\n",
      "Epoch 499/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 119154.8359 - mae: 239.9005 - val_loss: 71185.2109 - val_mae: 193.8092\n",
      "Epoch 500/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 116879.8750 - mae: 240.7345 - val_loss: 71229.0078 - val_mae: 193.8432\n",
      "Epoch 501/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 89784.8516 - mae: 197.6261 - val_loss: 71259.0078 - val_mae: 193.9055\n",
      "Epoch 502/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 102342.1562 - mae: 222.6463 - val_loss: 71313.2656 - val_mae: 194.0246\n",
      "Epoch 503/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 142058.6406 - mae: 244.1949 - val_loss: 71274.6406 - val_mae: 193.9185\n",
      "Epoch 504/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 120114.6328 - mae: 240.5813 - val_loss: 71063.4922 - val_mae: 193.4127\n",
      "Epoch 505/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 116227.7031 - mae: 224.6059 - val_loss: 70769.5156 - val_mae: 192.7141\n",
      "Epoch 506/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 115171.3281 - mae: 226.6161 - val_loss: 70781.9453 - val_mae: 192.7782\n",
      "Epoch 507/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 116900.5078 - mae: 234.7212 - val_loss: 70797.3594 - val_mae: 192.8106\n",
      "Epoch 508/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 118735.2578 - mae: 230.8742 - val_loss: 70790.9844 - val_mae: 192.7377\n",
      "Epoch 509/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 146184.0156 - mae: 246.1232 - val_loss: 70710.6016 - val_mae: 192.4646\n",
      "Epoch 510/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 105235.8281 - mae: 218.8103 - val_loss: 70533.4844 - val_mae: 192.0376\n",
      "Epoch 511/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 126799.4453 - mae: 231.0041 - val_loss: 70302.1328 - val_mae: 191.4841\n",
      "Epoch 512/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 121985.7500 - mae: 238.5763 - val_loss: 70228.1719 - val_mae: 191.3016\n",
      "Epoch 513/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 127891.5469 - mae: 242.0288 - val_loss: 70121.2188 - val_mae: 191.0505\n",
      "Epoch 514/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 113202.7109 - mae: 225.5963 - val_loss: 70199.5781 - val_mae: 191.2351\n",
      "Epoch 515/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 146128.2969 - mae: 251.3280 - val_loss: 70298.1875 - val_mae: 191.5286\n",
      "Epoch 516/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 102323.6016 - mae: 218.0971 - val_loss: 70669.3750 - val_mae: 192.4099\n",
      "Epoch 517/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 148272.5156 - mae: 245.8464 - val_loss: 70718.2500 - val_mae: 192.5538\n",
      "Epoch 518/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 122530.3750 - mae: 236.9881 - val_loss: 70720.9766 - val_mae: 192.6293\n",
      "Epoch 519/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 130231.1797 - mae: 233.5865 - val_loss: 70533.7969 - val_mae: 192.2130\n",
      "Epoch 520/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 130365.9688 - mae: 238.5913 - val_loss: 70524.1328 - val_mae: 192.0847\n",
      "Epoch 521/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 111409.6094 - mae: 227.6467 - val_loss: 70529.4766 - val_mae: 192.1669\n",
      "Epoch 522/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 142687.4844 - mae: 247.1647 - val_loss: 70308.5625 - val_mae: 191.7473\n",
      "Epoch 523/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 131851.3438 - mae: 246.7972 - val_loss: 70572.1562 - val_mae: 192.4251\n",
      "Epoch 524/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 117040.1484 - mae: 239.0265 - val_loss: 70876.3828 - val_mae: 193.1183\n",
      "Epoch 525/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 138749.0469 - mae: 248.1413 - val_loss: 70795.5156 - val_mae: 192.9514\n",
      "Epoch 526/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 136714.5000 - mae: 252.8815 - val_loss: 70922.9766 - val_mae: 193.2478\n",
      "Epoch 527/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 116308.8203 - mae: 221.1627 - val_loss: 71014.5859 - val_mae: 193.4326\n",
      "Epoch 528/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 119800.0000 - mae: 232.7249 - val_loss: 70797.9453 - val_mae: 192.8425\n",
      "Epoch 529/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 116545.7109 - mae: 227.7605 - val_loss: 70450.2188 - val_mae: 192.0254\n",
      "Epoch 530/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 148145.0781 - mae: 246.9907 - val_loss: 70430.9141 - val_mae: 192.0370\n",
      "Epoch 531/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 136735.6094 - mae: 248.3700 - val_loss: 70592.7891 - val_mae: 192.4168\n",
      "Epoch 532/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 154378.2344 - mae: 256.4978 - val_loss: 70686.2734 - val_mae: 192.7465\n",
      "Epoch 533/1000\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 127222.1016 - mae: 231.0729 - val_loss: 70822.8672 - val_mae: 193.1761\n",
      "Epoch 533: early stopping\n",
      "Restoring model weights from the end of the best epoch: 513.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Mean Absolute Error: 191.39626674298887\n",
      "Mean Squared Error: 64852.06107249966\n",
      "R-squared: 0.5978919198458285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=X_train.shape[1]))  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=3, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1)) \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "final = model.fit(X_train, y_train, validation_split=0.33, batch_size=50, epochs=1000, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AsadMunir\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 428923.8750 - mse: 428923.8750 - val_loss: 488585.9375 - val_mse: 488585.9375 - learning_rate: 0.0010\n",
      "Epoch 2/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 390857.8125 - mse: 390857.8125 - val_loss: 488535.0312 - val_mse: 488535.0312 - learning_rate: 0.0010\n",
      "Epoch 3/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 405044.1875 - mse: 405044.1875 - val_loss: 488491.5000 - val_mse: 488491.5000 - learning_rate: 0.0010\n",
      "Epoch 4/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 422259.4688 - mse: 422259.4688 - val_loss: 488453.7812 - val_mse: 488453.7812 - learning_rate: 0.0010\n",
      "Epoch 5/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 388681.0000 - mse: 388681.0000 - val_loss: 488420.7188 - val_mse: 488420.7188 - learning_rate: 0.0010\n",
      "Epoch 6/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 429928.4688 - mse: 429928.4688 - val_loss: 488389.5625 - val_mse: 488389.5625 - learning_rate: 0.0010\n",
      "Epoch 7/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 429173.0938 - mse: 429173.0938 - val_loss: 488360.9688 - val_mse: 488360.9688 - learning_rate: 0.0010\n",
      "Epoch 8/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 410898.5312 - mse: 410898.5312 - val_loss: 488331.5000 - val_mse: 488331.5000 - learning_rate: 0.0010\n",
      "Epoch 9/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 402628.5000 - mse: 402628.5000 - val_loss: 488299.9688 - val_mse: 488299.9688 - learning_rate: 0.0010\n",
      "Epoch 10/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 443539.5938 - mse: 443539.5938 - val_loss: 488264.2500 - val_mse: 488264.2500 - learning_rate: 0.0010\n",
      "Epoch 11/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 399941.4688 - mse: 399941.4688 - val_loss: 488223.1562 - val_mse: 488223.1562 - learning_rate: 0.0010\n",
      "Epoch 12/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 429280.5938 - mse: 429280.6250 - val_loss: 488169.9375 - val_mse: 488169.9375 - learning_rate: 0.0010\n",
      "Epoch 13/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 435663.3438 - mse: 435663.3438 - val_loss: 488099.3125 - val_mse: 488099.3125 - learning_rate: 0.0010\n",
      "Epoch 14/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 420596.4375 - mse: 420596.4375 - val_loss: 488013.8125 - val_mse: 488013.8125 - learning_rate: 0.0010\n",
      "Epoch 15/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 424147.0000 - mse: 424147.0000 - val_loss: 487912.6562 - val_mse: 487912.6562 - learning_rate: 0.0010\n",
      "Epoch 16/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 416765.2500 - mse: 416765.2500 - val_loss: 487802.7188 - val_mse: 487802.7188 - learning_rate: 0.0010\n",
      "Epoch 17/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 412775.2812 - mse: 412775.2812 - val_loss: 487681.0000 - val_mse: 487680.9688 - learning_rate: 0.0010\n",
      "Epoch 18/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 424148.3125 - mse: 424148.3125 - val_loss: 487541.8438 - val_mse: 487541.8438 - learning_rate: 0.0010\n",
      "Epoch 19/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 425234.9062 - mse: 425234.9062 - val_loss: 487386.6562 - val_mse: 487386.7188 - learning_rate: 0.0010\n",
      "Epoch 20/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 415996.0938 - mse: 415996.1250 - val_loss: 487208.9375 - val_mse: 487208.9375 - learning_rate: 0.0010\n",
      "Epoch 21/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 426712.0625 - mse: 426712.0625 - val_loss: 487014.5625 - val_mse: 487014.5625 - learning_rate: 0.0010\n",
      "Epoch 22/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 405095.6562 - mse: 405095.6562 - val_loss: 486795.2812 - val_mse: 486795.2812 - learning_rate: 0.0010\n",
      "Epoch 23/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 426815.6562 - mse: 426815.6562 - val_loss: 486554.2188 - val_mse: 486554.2188 - learning_rate: 0.0010\n",
      "Epoch 24/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 427519.2500 - mse: 427519.2500 - val_loss: 486291.0938 - val_mse: 486291.0938 - learning_rate: 0.0010\n",
      "Epoch 25/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 438977.1562 - mse: 438977.1562 - val_loss: 485998.5312 - val_mse: 485998.5312 - learning_rate: 0.0010\n",
      "Epoch 26/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 428274.4375 - mse: 428274.4375 - val_loss: 485661.4688 - val_mse: 485661.4688 - learning_rate: 0.0010\n",
      "Epoch 27/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 398758.5938 - mse: 398758.5938 - val_loss: 485286.0000 - val_mse: 485285.9375 - learning_rate: 0.0010\n",
      "Epoch 28/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 425109.9688 - mse: 425109.9688 - val_loss: 484863.0312 - val_mse: 484863.0312 - learning_rate: 0.0010\n",
      "Epoch 29/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 392171.9375 - mse: 392171.9375 - val_loss: 484393.2188 - val_mse: 484393.2188 - learning_rate: 0.0010\n",
      "Epoch 30/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 434533.8438 - mse: 434533.8438 - val_loss: 483861.7188 - val_mse: 483861.7188 - learning_rate: 0.0010\n",
      "Epoch 31/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 399851.7188 - mse: 399851.7188 - val_loss: 483286.9062 - val_mse: 483286.9688 - learning_rate: 0.0010\n",
      "Epoch 32/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 401996.8750 - mse: 401996.8750 - val_loss: 482653.8750 - val_mse: 482653.8750 - learning_rate: 0.0010\n",
      "Epoch 33/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 423046.7500 - mse: 423046.7500 - val_loss: 482011.9688 - val_mse: 482011.9688 - learning_rate: 0.0010\n",
      "Epoch 34/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 436646.0938 - mse: 436646.0938 - val_loss: 481300.7188 - val_mse: 481300.7188 - learning_rate: 0.0010\n",
      "Epoch 35/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 417351.2188 - mse: 417351.2188 - val_loss: 480539.6875 - val_mse: 480539.6875 - learning_rate: 0.0010\n",
      "Epoch 36/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 390337.7500 - mse: 390337.7500 - val_loss: 479698.1875 - val_mse: 479698.1875 - learning_rate: 0.0010\n",
      "Epoch 37/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 381474.1250 - mse: 381474.1250 - val_loss: 478780.0000 - val_mse: 478780.0000 - learning_rate: 0.0010\n",
      "Epoch 38/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 401784.6250 - mse: 401784.6250 - val_loss: 477794.1250 - val_mse: 477794.1250 - learning_rate: 0.0010\n",
      "Epoch 39/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 402986.7500 - mse: 402986.7500 - val_loss: 476725.9375 - val_mse: 476725.9375 - learning_rate: 0.0010\n",
      "Epoch 40/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 379486.2500 - mse: 379486.2500 - val_loss: 475587.5938 - val_mse: 475587.5938 - learning_rate: 0.0010\n",
      "Epoch 41/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 427905.8438 - mse: 427905.8438 - val_loss: 474330.2812 - val_mse: 474330.2812 - learning_rate: 0.0010\n",
      "Epoch 42/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 385277.3125 - mse: 385277.3125 - val_loss: 472988.5312 - val_mse: 472988.5312 - learning_rate: 0.0010\n",
      "Epoch 43/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 391972.5938 - mse: 391972.5625 - val_loss: 471547.0000 - val_mse: 471547.0000 - learning_rate: 0.0010\n",
      "Epoch 44/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 412140.0938 - mse: 412140.0938 - val_loss: 470000.0625 - val_mse: 470000.0625 - learning_rate: 0.0010\n",
      "Epoch 45/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 382752.4375 - mse: 382752.4375 - val_loss: 468373.5000 - val_mse: 468373.5000 - learning_rate: 0.0010\n",
      "Epoch 46/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 395885.7812 - mse: 395885.7812 - val_loss: 466651.7188 - val_mse: 466651.7188 - learning_rate: 0.0010\n",
      "Epoch 47/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 406561.3125 - mse: 406561.3125 - val_loss: 464817.2812 - val_mse: 464817.2812 - learning_rate: 0.0010\n",
      "Epoch 48/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 411813.5625 - mse: 411813.5625 - val_loss: 462810.8125 - val_mse: 462810.8125 - learning_rate: 0.0010\n",
      "Epoch 49/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 414175.9688 - mse: 414175.9688 - val_loss: 460717.1875 - val_mse: 460717.2188 - learning_rate: 0.0010\n",
      "Epoch 50/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 397883.3125 - mse: 397883.3125 - val_loss: 458572.2188 - val_mse: 458572.2188 - learning_rate: 0.0010\n",
      "Epoch 51/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 388665.5938 - mse: 388665.5938 - val_loss: 456340.2500 - val_mse: 456340.2500 - learning_rate: 0.0010\n",
      "Epoch 52/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 400325.6875 - mse: 400325.6875 - val_loss: 454018.5000 - val_mse: 454018.5000 - learning_rate: 0.0010\n",
      "Epoch 53/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 406651.2188 - mse: 406651.2188 - val_loss: 451637.5000 - val_mse: 451637.5000 - learning_rate: 0.0010\n",
      "Epoch 54/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 376634.5312 - mse: 376634.5312 - val_loss: 449054.3125 - val_mse: 449054.3125 - learning_rate: 0.0010\n",
      "Epoch 55/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 391144.2188 - mse: 391144.2188 - val_loss: 446374.8750 - val_mse: 446374.8750 - learning_rate: 0.0010\n",
      "Epoch 56/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 379475.5312 - mse: 379475.5312 - val_loss: 443627.7500 - val_mse: 443627.7500 - learning_rate: 0.0010\n",
      "Epoch 57/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 385956.5625 - mse: 385956.5625 - val_loss: 440836.9062 - val_mse: 440836.9062 - learning_rate: 0.0010\n",
      "Epoch 58/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 374367.5625 - mse: 374367.5625 - val_loss: 437975.7812 - val_mse: 437975.7812 - learning_rate: 0.0010\n",
      "Epoch 59/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 375877.0312 - mse: 375877.0312 - val_loss: 434957.7812 - val_mse: 434957.7812 - learning_rate: 0.0010\n",
      "Epoch 60/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 368901.6562 - mse: 368901.6562 - val_loss: 431938.9062 - val_mse: 431938.9062 - learning_rate: 0.0010\n",
      "Epoch 61/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 354865.1875 - mse: 354865.1875 - val_loss: 428793.8750 - val_mse: 428793.8750 - learning_rate: 0.0010\n",
      "Epoch 62/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 338227.3750 - mse: 338227.3750 - val_loss: 425519.5625 - val_mse: 425519.5625 - learning_rate: 0.0010\n",
      "Epoch 63/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 361443.5312 - mse: 361443.5312 - val_loss: 422055.2500 - val_mse: 422055.2500 - learning_rate: 0.0010\n",
      "Epoch 64/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 383326.6562 - mse: 383326.6562 - val_loss: 418635.5000 - val_mse: 418635.5000 - learning_rate: 0.0010\n",
      "Epoch 65/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 364058.2812 - mse: 364058.2812 - val_loss: 415237.0312 - val_mse: 415237.0312 - learning_rate: 0.0010\n",
      "Epoch 66/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 337531.7500 - mse: 337531.7500 - val_loss: 411729.5312 - val_mse: 411729.5312 - learning_rate: 0.0010\n",
      "Epoch 67/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 343888.4062 - mse: 343888.4062 - val_loss: 408075.0000 - val_mse: 408075.0000 - learning_rate: 0.0010\n",
      "Epoch 68/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 332034.2500 - mse: 332034.2500 - val_loss: 404243.3125 - val_mse: 404243.3125 - learning_rate: 0.0010\n",
      "Epoch 69/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 345626.6875 - mse: 345626.6875 - val_loss: 400443.4062 - val_mse: 400443.4062 - learning_rate: 0.0010\n",
      "Epoch 70/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 315388.9062 - mse: 315388.9062 - val_loss: 396693.3750 - val_mse: 396693.3750 - learning_rate: 0.0010\n",
      "Epoch 71/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 319520.7812 - mse: 319520.7500 - val_loss: 392721.2500 - val_mse: 392721.2500 - learning_rate: 0.0010\n",
      "Epoch 72/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 331805.7812 - mse: 331805.7812 - val_loss: 388843.2500 - val_mse: 388843.2500 - learning_rate: 0.0010\n",
      "Epoch 73/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 312063.4062 - mse: 312063.4062 - val_loss: 384786.5000 - val_mse: 384786.5000 - learning_rate: 0.0010\n",
      "Epoch 74/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 326413.2188 - mse: 326413.2188 - val_loss: 380643.7188 - val_mse: 380643.7188 - learning_rate: 0.0010\n",
      "Epoch 75/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 330628.0000 - mse: 330628.0000 - val_loss: 376608.2500 - val_mse: 376608.2500 - learning_rate: 0.0010\n",
      "Epoch 76/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 300463.7812 - mse: 300463.7812 - val_loss: 372695.6250 - val_mse: 372695.6250 - learning_rate: 0.0010\n",
      "Epoch 77/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 318444.4375 - mse: 318444.4375 - val_loss: 368642.5938 - val_mse: 368642.5938 - learning_rate: 0.0010\n",
      "Epoch 78/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 303777.3438 - mse: 303777.3438 - val_loss: 364488.3125 - val_mse: 364488.3125 - learning_rate: 0.0010\n",
      "Epoch 79/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 286697.2188 - mse: 286697.2188 - val_loss: 360319.5000 - val_mse: 360319.5000 - learning_rate: 0.0010\n",
      "Epoch 80/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 284411.6250 - mse: 284411.6250 - val_loss: 356075.4062 - val_mse: 356075.4062 - learning_rate: 0.0010\n",
      "Epoch 81/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 296494.8750 - mse: 296494.8750 - val_loss: 351923.0938 - val_mse: 351923.0938 - learning_rate: 0.0010\n",
      "Epoch 82/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 279935.3438 - mse: 279935.3438 - val_loss: 347684.2812 - val_mse: 347684.2812 - learning_rate: 0.0010\n",
      "Epoch 83/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 292539.2188 - mse: 292539.2188 - val_loss: 343467.2812 - val_mse: 343467.2812 - learning_rate: 0.0010\n",
      "Epoch 84/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 288511.2188 - mse: 288511.2188 - val_loss: 339252.5312 - val_mse: 339252.5312 - learning_rate: 0.0010\n",
      "Epoch 85/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 282792.6250 - mse: 282792.6562 - val_loss: 334899.3750 - val_mse: 334899.3750 - learning_rate: 0.0010\n",
      "Epoch 86/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 280922.6562 - mse: 280922.6562 - val_loss: 330541.1875 - val_mse: 330541.1875 - learning_rate: 0.0010\n",
      "Epoch 87/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 274604.9062 - mse: 274604.9062 - val_loss: 326172.5625 - val_mse: 326172.5625 - learning_rate: 0.0010\n",
      "Epoch 88/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 278560.3750 - mse: 278560.3750 - val_loss: 321758.4688 - val_mse: 321758.4688 - learning_rate: 0.0010\n",
      "Epoch 89/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 255199.3438 - mse: 255199.3438 - val_loss: 317380.5000 - val_mse: 317380.5000 - learning_rate: 0.0010\n",
      "Epoch 90/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 267836.9375 - mse: 267836.9375 - val_loss: 313196.9062 - val_mse: 313196.9062 - learning_rate: 0.0010\n",
      "Epoch 91/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 251295.5156 - mse: 251295.5156 - val_loss: 309040.3125 - val_mse: 309040.3125 - learning_rate: 0.0010\n",
      "Epoch 92/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 274412.3125 - mse: 274412.3438 - val_loss: 304698.7500 - val_mse: 304698.7812 - learning_rate: 0.0010\n",
      "Epoch 93/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 240829.6094 - mse: 240829.6094 - val_loss: 300426.8750 - val_mse: 300426.8750 - learning_rate: 0.0010\n",
      "Epoch 94/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 250985.9531 - mse: 250985.9531 - val_loss: 296160.0625 - val_mse: 296160.0625 - learning_rate: 0.0010\n",
      "Epoch 95/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 228546.7812 - mse: 228546.7656 - val_loss: 291855.1250 - val_mse: 291855.1562 - learning_rate: 0.0010\n",
      "Epoch 96/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 235609.7031 - mse: 235609.7031 - val_loss: 287686.2188 - val_mse: 287686.2188 - learning_rate: 0.0010\n",
      "Epoch 97/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 248768.9531 - mse: 248768.9531 - val_loss: 283759.3438 - val_mse: 283759.3438 - learning_rate: 0.0010\n",
      "Epoch 98/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 240276.7812 - mse: 240276.7812 - val_loss: 279860.1250 - val_mse: 279860.1250 - learning_rate: 0.0010\n",
      "Epoch 99/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 218474.9062 - mse: 218474.9062 - val_loss: 276104.5625 - val_mse: 276104.5625 - learning_rate: 0.0010\n",
      "Epoch 100/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 224432.2500 - mse: 224432.2500 - val_loss: 272193.9688 - val_mse: 272193.9688 - learning_rate: 0.0010\n",
      "Epoch 101/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 245562.9219 - mse: 245562.9219 - val_loss: 268280.4062 - val_mse: 268280.4062 - learning_rate: 0.0010\n",
      "Epoch 102/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 204010.3281 - mse: 204010.3125 - val_loss: 264300.6250 - val_mse: 264300.6250 - learning_rate: 0.0010\n",
      "Epoch 103/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 225780.5000 - mse: 225780.5156 - val_loss: 260535.4062 - val_mse: 260535.4062 - learning_rate: 0.0010\n",
      "Epoch 104/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 202136.9844 - mse: 202136.9844 - val_loss: 256941.3125 - val_mse: 256941.3125 - learning_rate: 0.0010\n",
      "Epoch 105/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 217410.5000 - mse: 217410.5000 - val_loss: 253214.5156 - val_mse: 253214.5156 - learning_rate: 0.0010\n",
      "Epoch 106/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 219574.6562 - mse: 219574.6562 - val_loss: 249432.1094 - val_mse: 249432.1094 - learning_rate: 0.0010\n",
      "Epoch 107/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 209974.4375 - mse: 209974.4375 - val_loss: 245745.4844 - val_mse: 245745.4844 - learning_rate: 0.0010\n",
      "Epoch 108/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 205445.3281 - mse: 205445.3281 - val_loss: 242163.5938 - val_mse: 242163.5938 - learning_rate: 0.0010\n",
      "Epoch 109/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 212412.2656 - mse: 212412.2812 - val_loss: 238679.3750 - val_mse: 238679.3750 - learning_rate: 0.0010\n",
      "Epoch 110/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 213403.9062 - mse: 213403.9062 - val_loss: 235065.8438 - val_mse: 235065.8438 - learning_rate: 0.0010\n",
      "Epoch 111/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 213166.9062 - mse: 213166.9062 - val_loss: 231407.5781 - val_mse: 231407.5938 - learning_rate: 0.0010\n",
      "Epoch 112/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 194303.7031 - mse: 194303.7031 - val_loss: 227857.4688 - val_mse: 227857.4688 - learning_rate: 0.0010\n",
      "Epoch 113/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 193942.8594 - mse: 193942.8594 - val_loss: 224593.5625 - val_mse: 224593.5625 - learning_rate: 0.0010\n",
      "Epoch 114/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 192522.2812 - mse: 192522.2656 - val_loss: 221347.0625 - val_mse: 221347.0625 - learning_rate: 0.0010\n",
      "Epoch 115/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 191596.0156 - mse: 191596.0156 - val_loss: 218192.5469 - val_mse: 218192.5469 - learning_rate: 0.0010\n",
      "Epoch 116/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 200604.2188 - mse: 200604.2188 - val_loss: 214838.1406 - val_mse: 214838.1406 - learning_rate: 0.0010\n",
      "Epoch 117/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 192266.2344 - mse: 192266.2344 - val_loss: 211495.5781 - val_mse: 211495.5781 - learning_rate: 0.0010\n",
      "Epoch 118/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 198409.1719 - mse: 198409.1719 - val_loss: 208157.8125 - val_mse: 208157.8125 - learning_rate: 0.0010\n",
      "Epoch 119/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 188509.3125 - mse: 188509.3125 - val_loss: 204892.3281 - val_mse: 204892.3281 - learning_rate: 0.0010\n",
      "Epoch 120/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 188195.4688 - mse: 188195.4688 - val_loss: 201619.9375 - val_mse: 201619.9375 - learning_rate: 0.0010\n",
      "Epoch 121/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 164843.1719 - mse: 164843.1719 - val_loss: 198536.7344 - val_mse: 198536.7344 - learning_rate: 0.0010\n",
      "Epoch 122/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 175360.0156 - mse: 175360.0156 - val_loss: 195366.1250 - val_mse: 195366.1250 - learning_rate: 0.0010\n",
      "Epoch 123/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 175844.4844 - mse: 175844.4844 - val_loss: 192248.2500 - val_mse: 192248.2500 - learning_rate: 0.0010\n",
      "Epoch 124/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 176601.4375 - mse: 176601.4375 - val_loss: 189249.0156 - val_mse: 189249.0312 - learning_rate: 0.0010\n",
      "Epoch 125/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 179186.1719 - mse: 179186.1562 - val_loss: 186184.4219 - val_mse: 186184.4219 - learning_rate: 0.0010\n",
      "Epoch 126/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 163163.2969 - mse: 163163.2969 - val_loss: 183333.2969 - val_mse: 183333.2812 - learning_rate: 0.0010\n",
      "Epoch 127/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 156488.2031 - mse: 156488.2031 - val_loss: 180483.1250 - val_mse: 180483.1250 - learning_rate: 0.0010\n",
      "Epoch 128/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 173698.7812 - mse: 173698.7812 - val_loss: 177761.3438 - val_mse: 177761.3438 - learning_rate: 0.0010\n",
      "Epoch 129/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 140975.1406 - mse: 140975.1406 - val_loss: 175054.7031 - val_mse: 175054.7031 - learning_rate: 0.0010\n",
      "Epoch 130/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 181845.8906 - mse: 181845.8906 - val_loss: 172290.1875 - val_mse: 172290.1875 - learning_rate: 0.0010\n",
      "Epoch 131/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 146333.3125 - mse: 146333.3125 - val_loss: 169862.9688 - val_mse: 169862.9844 - learning_rate: 0.0010\n",
      "Epoch 132/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 182922.2656 - mse: 182922.2656 - val_loss: 167165.2656 - val_mse: 167165.2812 - learning_rate: 0.0010\n",
      "Epoch 133/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 159723.9219 - mse: 159723.9375 - val_loss: 164516.7344 - val_mse: 164516.7344 - learning_rate: 0.0010\n",
      "Epoch 134/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 172298.3906 - mse: 172298.3906 - val_loss: 162130.0625 - val_mse: 162130.0625 - learning_rate: 0.0010\n",
      "Epoch 135/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 164260.8594 - mse: 164260.8594 - val_loss: 160088.2500 - val_mse: 160088.2500 - learning_rate: 0.0010\n",
      "Epoch 136/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 154628.5625 - mse: 154628.5625 - val_loss: 157811.5625 - val_mse: 157811.5625 - learning_rate: 0.0010\n",
      "Epoch 137/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 151019.6406 - mse: 151019.6406 - val_loss: 155375.3594 - val_mse: 155375.3594 - learning_rate: 0.0010\n",
      "Epoch 138/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 150112.8906 - mse: 150112.8750 - val_loss: 153242.6719 - val_mse: 153242.6719 - learning_rate: 0.0010\n",
      "Epoch 139/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 151522.0312 - mse: 151522.0312 - val_loss: 150943.3438 - val_mse: 150943.3438 - learning_rate: 0.0010\n",
      "Epoch 140/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 150479.2344 - mse: 150479.2344 - val_loss: 148824.5312 - val_mse: 148824.5312 - learning_rate: 0.0010\n",
      "Epoch 141/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 153194.4531 - mse: 153194.4531 - val_loss: 146720.3281 - val_mse: 146720.3281 - learning_rate: 0.0010\n",
      "Epoch 142/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 138840.2188 - mse: 138840.2188 - val_loss: 144765.3750 - val_mse: 144765.3750 - learning_rate: 0.0010\n",
      "Epoch 143/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 146657.0469 - mse: 146657.0469 - val_loss: 142654.4219 - val_mse: 142654.4219 - learning_rate: 0.0010\n",
      "Epoch 144/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 150020.1875 - mse: 150020.1875 - val_loss: 140732.4688 - val_mse: 140732.4688 - learning_rate: 0.0010\n",
      "Epoch 145/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 147781.0781 - mse: 147781.0781 - val_loss: 138945.1406 - val_mse: 138945.1406 - learning_rate: 0.0010\n",
      "Epoch 146/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 159249.5938 - mse: 159249.6094 - val_loss: 136999.9219 - val_mse: 136999.9219 - learning_rate: 0.0010\n",
      "Epoch 147/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 151760.6875 - mse: 151760.7031 - val_loss: 135059.2812 - val_mse: 135059.2812 - learning_rate: 0.0010\n",
      "Epoch 148/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 148736.2969 - mse: 148736.2969 - val_loss: 133346.0000 - val_mse: 133346.0000 - learning_rate: 0.0010\n",
      "Epoch 149/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 141729.1406 - mse: 141729.1406 - val_loss: 131536.1250 - val_mse: 131536.1250 - learning_rate: 0.0010\n",
      "Epoch 150/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 127250.3125 - mse: 127250.3125 - val_loss: 129872.8984 - val_mse: 129872.8984 - learning_rate: 0.0010\n",
      "Epoch 151/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 138613.3594 - mse: 138613.3594 - val_loss: 127929.4141 - val_mse: 127929.4141 - learning_rate: 0.0010\n",
      "Epoch 152/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 138741.4062 - mse: 138741.4062 - val_loss: 126175.6875 - val_mse: 126175.6875 - learning_rate: 0.0010\n",
      "Epoch 153/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 128879.9688 - mse: 128879.9531 - val_loss: 124425.6016 - val_mse: 124425.6016 - learning_rate: 0.0010\n",
      "Epoch 154/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 127498.3750 - mse: 127498.3750 - val_loss: 122813.5156 - val_mse: 122813.5156 - learning_rate: 0.0010\n",
      "Epoch 155/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 130927.7969 - mse: 130927.7969 - val_loss: 121294.7344 - val_mse: 121294.7344 - learning_rate: 0.0010\n",
      "Epoch 156/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 130258.2969 - mse: 130258.2969 - val_loss: 119874.8906 - val_mse: 119874.8906 - learning_rate: 0.0010\n",
      "Epoch 157/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 135931.5000 - mse: 135931.5000 - val_loss: 118305.6016 - val_mse: 118305.6016 - learning_rate: 0.0010\n",
      "Epoch 158/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 134470.5781 - mse: 134470.5781 - val_loss: 116948.8359 - val_mse: 116948.8359 - learning_rate: 0.0010\n",
      "Epoch 159/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 123008.5391 - mse: 123008.5391 - val_loss: 115579.1172 - val_mse: 115579.1172 - learning_rate: 0.0010\n",
      "Epoch 160/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 133783.3438 - mse: 133783.3438 - val_loss: 114198.2422 - val_mse: 114198.2422 - learning_rate: 0.0010\n",
      "Epoch 161/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 122558.4531 - mse: 122558.4531 - val_loss: 112950.7109 - val_mse: 112950.7109 - learning_rate: 0.0010\n",
      "Epoch 162/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 118169.6953 - mse: 118169.6953 - val_loss: 111618.1172 - val_mse: 111618.1172 - learning_rate: 0.0010\n",
      "Epoch 163/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 143306.0469 - mse: 143306.0469 - val_loss: 110412.4844 - val_mse: 110412.4844 - learning_rate: 0.0010\n",
      "Epoch 164/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 137257.9375 - mse: 137257.9375 - val_loss: 109334.1719 - val_mse: 109334.1719 - learning_rate: 0.0010\n",
      "Epoch 165/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 121315.1406 - mse: 121315.1406 - val_loss: 107961.0078 - val_mse: 107961.0078 - learning_rate: 0.0010\n",
      "Epoch 166/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 126166.3828 - mse: 126166.3828 - val_loss: 106873.6250 - val_mse: 106873.6328 - learning_rate: 0.0010\n",
      "Epoch 167/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 124460.6641 - mse: 124460.6641 - val_loss: 105720.1797 - val_mse: 105720.1797 - learning_rate: 0.0010\n",
      "Epoch 168/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 126932.9609 - mse: 126932.9688 - val_loss: 104787.6094 - val_mse: 104787.6094 - learning_rate: 0.0010\n",
      "Epoch 169/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 123294.3516 - mse: 123294.3516 - val_loss: 103715.4844 - val_mse: 103715.4922 - learning_rate: 0.0010\n",
      "Epoch 170/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 125956.9688 - mse: 125956.9766 - val_loss: 102471.0234 - val_mse: 102471.0234 - learning_rate: 0.0010\n",
      "Epoch 171/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 128814.4453 - mse: 128814.4453 - val_loss: 101225.2188 - val_mse: 101225.2188 - learning_rate: 0.0010\n",
      "Epoch 172/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 124098.9922 - mse: 124098.9922 - val_loss: 100400.0391 - val_mse: 100400.0547 - learning_rate: 0.0010\n",
      "Epoch 173/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 116651.6641 - mse: 116651.6641 - val_loss: 99643.9688 - val_mse: 99643.9688 - learning_rate: 0.0010\n",
      "Epoch 174/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 130244.0000 - mse: 130244.0000 - val_loss: 98638.4219 - val_mse: 98638.4219 - learning_rate: 0.0010\n",
      "Epoch 175/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 104864.7344 - mse: 104864.7344 - val_loss: 97422.1016 - val_mse: 97422.0938 - learning_rate: 0.0010\n",
      "Epoch 176/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 108306.2266 - mse: 108306.2266 - val_loss: 96334.9453 - val_mse: 96334.9453 - learning_rate: 0.0010\n",
      "Epoch 177/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 95684.1719 - mse: 95684.1719 - val_loss: 95145.4297 - val_mse: 95145.4297 - learning_rate: 0.0010\n",
      "Epoch 178/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 108474.5469 - mse: 108474.5469 - val_loss: 94180.1797 - val_mse: 94180.1797 - learning_rate: 0.0010\n",
      "Epoch 179/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 107511.5625 - mse: 107511.5625 - val_loss: 93205.3594 - val_mse: 93205.3594 - learning_rate: 0.0010\n",
      "Epoch 180/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 109655.7812 - mse: 109655.7812 - val_loss: 92356.0312 - val_mse: 92356.0312 - learning_rate: 0.0010\n",
      "Epoch 181/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 94800.5938 - mse: 94800.5938 - val_loss: 91518.5547 - val_mse: 91518.5547 - learning_rate: 0.0010\n",
      "Epoch 182/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 108404.0625 - mse: 108404.0625 - val_loss: 90705.7500 - val_mse: 90705.7578 - learning_rate: 0.0010\n",
      "Epoch 183/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 107994.2500 - mse: 107994.2500 - val_loss: 89941.7969 - val_mse: 89941.7969 - learning_rate: 0.0010\n",
      "Epoch 184/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 117598.6328 - mse: 117598.6484 - val_loss: 89280.7266 - val_mse: 89280.7266 - learning_rate: 0.0010\n",
      "Epoch 185/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 118979.4375 - mse: 118979.4375 - val_loss: 88662.7344 - val_mse: 88662.7344 - learning_rate: 0.0010\n",
      "Epoch 186/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 97505.9844 - mse: 97505.9766 - val_loss: 88054.4062 - val_mse: 88054.4062 - learning_rate: 0.0010\n",
      "Epoch 187/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 107710.6250 - mse: 107710.6250 - val_loss: 87414.4844 - val_mse: 87414.4688 - learning_rate: 0.0010\n",
      "Epoch 188/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 108619.1484 - mse: 108619.1484 - val_loss: 86834.3438 - val_mse: 86834.3438 - learning_rate: 0.0010\n",
      "Epoch 189/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 107368.5391 - mse: 107368.5391 - val_loss: 86199.8906 - val_mse: 86199.8906 - learning_rate: 0.0010\n",
      "Epoch 190/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 109656.7891 - mse: 109656.7891 - val_loss: 85490.7812 - val_mse: 85490.7734 - learning_rate: 0.0010\n",
      "Epoch 191/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 110801.6875 - mse: 110801.6875 - val_loss: 84781.5234 - val_mse: 84781.5234 - learning_rate: 0.0010\n",
      "Epoch 192/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 103661.0781 - mse: 103661.0781 - val_loss: 83984.5156 - val_mse: 83984.5156 - learning_rate: 0.0010\n",
      "Epoch 193/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 114247.5000 - mse: 114247.5000 - val_loss: 83316.5625 - val_mse: 83316.5625 - learning_rate: 0.0010\n",
      "Epoch 194/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 112955.2266 - mse: 112955.2266 - val_loss: 82935.4766 - val_mse: 82935.4766 - learning_rate: 0.0010\n",
      "Epoch 195/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 99348.1953 - mse: 99348.1953 - val_loss: 82486.4922 - val_mse: 82486.4922 - learning_rate: 0.0010\n",
      "Epoch 196/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 102016.9531 - mse: 102016.9531 - val_loss: 81836.8828 - val_mse: 81836.8828 - learning_rate: 0.0010\n",
      "Epoch 197/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 100325.6016 - mse: 100325.6016 - val_loss: 81280.5469 - val_mse: 81280.5469 - learning_rate: 0.0010\n",
      "Epoch 198/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 102196.6953 - mse: 102196.6953 - val_loss: 80745.9141 - val_mse: 80745.9141 - learning_rate: 0.0010\n",
      "Epoch 199/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 99258.3516 - mse: 99258.3516 - val_loss: 80165.0781 - val_mse: 80165.0781 - learning_rate: 0.0010\n",
      "Epoch 200/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 118642.9297 - mse: 118642.9375 - val_loss: 79631.0547 - val_mse: 79631.0547 - learning_rate: 0.0010\n",
      "Epoch 201/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 117288.4297 - mse: 117288.4297 - val_loss: 79172.7109 - val_mse: 79172.7109 - learning_rate: 0.0010\n",
      "Epoch 202/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 97677.4609 - mse: 97677.4609 - val_loss: 78720.9375 - val_mse: 78720.9375 - learning_rate: 0.0010\n",
      "Epoch 203/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 112316.5625 - mse: 112316.5625 - val_loss: 78170.5547 - val_mse: 78170.5547 - learning_rate: 0.0010\n",
      "Epoch 204/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 104925.0469 - mse: 104925.0469 - val_loss: 77785.5000 - val_mse: 77785.5000 - learning_rate: 0.0010\n",
      "Epoch 205/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 116101.1094 - mse: 116101.1094 - val_loss: 77333.0625 - val_mse: 77333.0625 - learning_rate: 0.0010\n",
      "Epoch 206/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 100889.4219 - mse: 100889.4219 - val_loss: 76877.2422 - val_mse: 76877.2422 - learning_rate: 0.0010\n",
      "Epoch 207/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 110627.3047 - mse: 110627.3047 - val_loss: 76589.6016 - val_mse: 76589.6016 - learning_rate: 0.0010\n",
      "Epoch 208/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 99610.7266 - mse: 99610.7266 - val_loss: 76155.2969 - val_mse: 76155.2969 - learning_rate: 0.0010\n",
      "Epoch 209/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 113526.0469 - mse: 113526.0469 - val_loss: 75610.5000 - val_mse: 75610.5000 - learning_rate: 0.0010\n",
      "Epoch 210/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 104795.1719 - mse: 104795.1719 - val_loss: 75148.3516 - val_mse: 75148.3516 - learning_rate: 0.0010\n",
      "Epoch 211/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 108741.4453 - mse: 108741.4453 - val_loss: 74766.5938 - val_mse: 74766.5938 - learning_rate: 0.0010\n",
      "Epoch 212/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 106401.3281 - mse: 106401.3281 - val_loss: 74757.0078 - val_mse: 74757.0078 - learning_rate: 0.0010\n",
      "Epoch 213/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 105035.4688 - mse: 105035.4766 - val_loss: 74490.2031 - val_mse: 74490.2031 - learning_rate: 0.0010\n",
      "Epoch 214/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 120446.3047 - mse: 120446.3047 - val_loss: 73994.6562 - val_mse: 73994.6562 - learning_rate: 0.0010\n",
      "Epoch 215/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 99919.7422 - mse: 99919.7422 - val_loss: 73707.5781 - val_mse: 73707.5781 - learning_rate: 0.0010\n",
      "Epoch 216/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 101124.5391 - mse: 101124.5391 - val_loss: 73539.1328 - val_mse: 73539.1328 - learning_rate: 0.0010\n",
      "Epoch 217/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 95944.5078 - mse: 95944.5078 - val_loss: 73297.4844 - val_mse: 73297.4766 - learning_rate: 0.0010\n",
      "Epoch 218/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 110206.5938 - mse: 110206.5938 - val_loss: 72970.7891 - val_mse: 72970.7891 - learning_rate: 0.0010\n",
      "Epoch 219/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 98055.8125 - mse: 98055.8125 - val_loss: 72741.0781 - val_mse: 72741.0781 - learning_rate: 0.0010\n",
      "Epoch 220/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 108901.7344 - mse: 108901.7344 - val_loss: 72524.9844 - val_mse: 72524.9844 - learning_rate: 0.0010\n",
      "Epoch 221/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 107090.0234 - mse: 107090.0234 - val_loss: 72356.8516 - val_mse: 72356.8516 - learning_rate: 0.0010\n",
      "Epoch 222/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 101401.3984 - mse: 101401.3984 - val_loss: 72113.1875 - val_mse: 72113.1875 - learning_rate: 0.0010\n",
      "Epoch 223/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 113749.6719 - mse: 113749.6719 - val_loss: 71779.3984 - val_mse: 71779.3984 - learning_rate: 0.0010\n",
      "Epoch 224/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 92419.3828 - mse: 92419.3828 - val_loss: 71467.5781 - val_mse: 71467.5781 - learning_rate: 0.0010\n",
      "Epoch 225/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 119943.0391 - mse: 119943.0391 - val_loss: 71233.1797 - val_mse: 71233.1797 - learning_rate: 0.0010\n",
      "Epoch 226/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 113478.2500 - mse: 113478.2500 - val_loss: 70987.6953 - val_mse: 70987.6953 - learning_rate: 0.0010\n",
      "Epoch 227/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 94340.3828 - mse: 94340.3828 - val_loss: 70755.8984 - val_mse: 70755.8984 - learning_rate: 0.0010\n",
      "Epoch 228/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 119018.0547 - mse: 119018.0547 - val_loss: 70586.8750 - val_mse: 70586.8750 - learning_rate: 0.0010\n",
      "Epoch 229/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 93767.2266 - mse: 93767.2266 - val_loss: 70567.8281 - val_mse: 70567.8281 - learning_rate: 0.0010\n",
      "Epoch 230/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 107477.9766 - mse: 107477.9766 - val_loss: 70367.0000 - val_mse: 70367.0000 - learning_rate: 0.0010\n",
      "Epoch 231/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 95443.4219 - mse: 95443.4219 - val_loss: 70181.1094 - val_mse: 70181.1094 - learning_rate: 0.0010\n",
      "Epoch 232/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 105370.7031 - mse: 105370.7031 - val_loss: 69778.2891 - val_mse: 69778.2891 - learning_rate: 0.0010\n",
      "Epoch 233/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 104188.4531 - mse: 104188.4531 - val_loss: 69491.0391 - val_mse: 69491.0391 - learning_rate: 0.0010\n",
      "Epoch 234/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 106555.6953 - mse: 106555.6953 - val_loss: 69174.3828 - val_mse: 69174.3828 - learning_rate: 0.0010\n",
      "Epoch 235/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 86374.5000 - mse: 86374.5000 - val_loss: 68947.6797 - val_mse: 68947.6797 - learning_rate: 0.0010\n",
      "Epoch 236/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 104109.5469 - mse: 104109.5469 - val_loss: 68751.0703 - val_mse: 68751.0703 - learning_rate: 0.0010\n",
      "Epoch 237/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 95874.7969 - mse: 95874.7969 - val_loss: 68379.1328 - val_mse: 68379.1328 - learning_rate: 0.0010\n",
      "Epoch 238/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 98961.5781 - mse: 98961.5781 - val_loss: 68124.1797 - val_mse: 68124.1797 - learning_rate: 0.0010\n",
      "Epoch 239/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 88001.2969 - mse: 88001.2969 - val_loss: 67996.0859 - val_mse: 67996.0859 - learning_rate: 0.0010\n",
      "Epoch 240/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 102488.7812 - mse: 102488.7812 - val_loss: 67728.6328 - val_mse: 67728.6406 - learning_rate: 0.0010\n",
      "Epoch 241/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 101987.6484 - mse: 101987.6484 - val_loss: 67570.0312 - val_mse: 67570.0312 - learning_rate: 0.0010\n",
      "Epoch 242/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 103765.1641 - mse: 103765.1641 - val_loss: 67424.4922 - val_mse: 67424.4922 - learning_rate: 0.0010\n",
      "Epoch 243/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 102242.5781 - mse: 102242.5781 - val_loss: 67184.1797 - val_mse: 67184.1797 - learning_rate: 0.0010\n",
      "Epoch 244/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 102674.6250 - mse: 102674.6250 - val_loss: 67135.7578 - val_mse: 67135.7578 - learning_rate: 0.0010\n",
      "Epoch 245/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 97440.3594 - mse: 97440.3594 - val_loss: 67182.3516 - val_mse: 67182.3516 - learning_rate: 0.0010\n",
      "Epoch 246/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 95599.3203 - mse: 95599.3203 - val_loss: 66976.7266 - val_mse: 66976.7266 - learning_rate: 0.0010\n",
      "Epoch 247/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 106109.1250 - mse: 106109.1250 - val_loss: 66859.8906 - val_mse: 66859.8906 - learning_rate: 0.0010\n",
      "Epoch 248/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 98535.7969 - mse: 98535.7969 - val_loss: 66798.1406 - val_mse: 66798.1406 - learning_rate: 0.0010\n",
      "Epoch 249/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 104820.3672 - mse: 104820.3672 - val_loss: 66583.7422 - val_mse: 66583.7422 - learning_rate: 0.0010\n",
      "Epoch 250/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 97832.9062 - mse: 97832.9062 - val_loss: 66483.5547 - val_mse: 66483.5547 - learning_rate: 0.0010\n",
      "Epoch 251/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 91005.1484 - mse: 91005.1484 - val_loss: 66475.7656 - val_mse: 66475.7656 - learning_rate: 0.0010\n",
      "Epoch 252/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 97930.8438 - mse: 97930.8438 - val_loss: 66109.8438 - val_mse: 66109.8438 - learning_rate: 0.0010\n",
      "Epoch 253/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 89203.5312 - mse: 89203.5312 - val_loss: 65826.4453 - val_mse: 65826.4453 - learning_rate: 0.0010\n",
      "Epoch 254/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 102819.8906 - mse: 102819.8906 - val_loss: 65553.9297 - val_mse: 65553.9297 - learning_rate: 0.0010\n",
      "Epoch 255/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 93395.6641 - mse: 93395.6641 - val_loss: 65410.0430 - val_mse: 65410.0430 - learning_rate: 0.0010\n",
      "Epoch 256/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 97589.0391 - mse: 97589.0391 - val_loss: 65195.1562 - val_mse: 65195.1562 - learning_rate: 0.0010\n",
      "Epoch 257/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 85985.9766 - mse: 85985.9766 - val_loss: 64865.6367 - val_mse: 64865.6367 - learning_rate: 0.0010\n",
      "Epoch 258/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 94298.9375 - mse: 94298.9375 - val_loss: 64758.1758 - val_mse: 64758.1758 - learning_rate: 0.0010\n",
      "Epoch 259/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 97675.2109 - mse: 97675.2109 - val_loss: 64578.9961 - val_mse: 64578.9961 - learning_rate: 0.0010\n",
      "Epoch 260/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 97652.8984 - mse: 97652.8984 - val_loss: 64263.4297 - val_mse: 64263.4297 - learning_rate: 0.0010\n",
      "Epoch 261/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 82423.6797 - mse: 82423.6797 - val_loss: 64172.9336 - val_mse: 64172.9336 - learning_rate: 0.0010\n",
      "Epoch 262/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 101398.3125 - mse: 101398.3125 - val_loss: 63999.5000 - val_mse: 63999.5000 - learning_rate: 0.0010\n",
      "Epoch 263/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 84169.9688 - mse: 84169.9688 - val_loss: 63953.6484 - val_mse: 63953.6484 - learning_rate: 0.0010\n",
      "Epoch 264/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 96301.1016 - mse: 96301.1016 - val_loss: 63853.5938 - val_mse: 63853.5938 - learning_rate: 0.0010\n",
      "Epoch 265/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 97498.0625 - mse: 97498.0625 - val_loss: 63658.8711 - val_mse: 63658.8711 - learning_rate: 0.0010\n",
      "Epoch 266/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 104137.2734 - mse: 104137.2734 - val_loss: 63265.7344 - val_mse: 63265.7344 - learning_rate: 0.0010\n",
      "Epoch 267/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 89231.6172 - mse: 89231.6172 - val_loss: 62946.8789 - val_mse: 62946.8789 - learning_rate: 0.0010\n",
      "Epoch 268/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 104362.2656 - mse: 104362.2656 - val_loss: 62776.9766 - val_mse: 62776.9766 - learning_rate: 0.0010\n",
      "Epoch 269/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 91378.0547 - mse: 91378.0547 - val_loss: 62754.7227 - val_mse: 62754.7227 - learning_rate: 0.0010\n",
      "Epoch 270/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 111537.4688 - mse: 111537.4688 - val_loss: 62895.8164 - val_mse: 62895.8164 - learning_rate: 0.0010\n",
      "Epoch 271/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 93184.9766 - mse: 93184.9766 - val_loss: 62896.6094 - val_mse: 62896.6094 - learning_rate: 0.0010\n",
      "Epoch 272/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 89076.4375 - mse: 89076.4375 - val_loss: 62684.8633 - val_mse: 62684.8633 - learning_rate: 0.0010\n",
      "Epoch 273/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 89961.0703 - mse: 89961.0781 - val_loss: 62543.4258 - val_mse: 62543.4258 - learning_rate: 0.0010\n",
      "Epoch 274/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 91635.4062 - mse: 91635.4062 - val_loss: 62481.7344 - val_mse: 62481.7344 - learning_rate: 0.0010\n",
      "Epoch 275/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 81736.1641 - mse: 81736.1641 - val_loss: 62429.7695 - val_mse: 62429.7695 - learning_rate: 0.0010\n",
      "Epoch 276/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 92123.6094 - mse: 92123.6094 - val_loss: 62209.4102 - val_mse: 62209.4180 - learning_rate: 0.0010\n",
      "Epoch 277/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 95980.3203 - mse: 95980.3203 - val_loss: 62010.3633 - val_mse: 62010.3633 - learning_rate: 0.0010\n",
      "Epoch 278/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 110207.6172 - mse: 110207.6172 - val_loss: 61922.7578 - val_mse: 61922.7578 - learning_rate: 0.0010\n",
      "Epoch 279/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 98229.8203 - mse: 98229.8203 - val_loss: 61813.6367 - val_mse: 61813.6367 - learning_rate: 0.0010\n",
      "Epoch 280/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 87423.3984 - mse: 87423.3984 - val_loss: 61517.9453 - val_mse: 61517.9453 - learning_rate: 0.0010\n",
      "Epoch 281/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 95244.6328 - mse: 95244.6328 - val_loss: 61253.6289 - val_mse: 61253.6289 - learning_rate: 0.0010\n",
      "Epoch 282/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 93879.7656 - mse: 93879.7578 - val_loss: 61170.4688 - val_mse: 61170.4688 - learning_rate: 0.0010\n",
      "Epoch 283/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 93349.5156 - mse: 93349.5156 - val_loss: 61139.2070 - val_mse: 61139.2070 - learning_rate: 0.0010\n",
      "Epoch 284/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 97051.7812 - mse: 97051.7812 - val_loss: 61212.0625 - val_mse: 61212.0547 - learning_rate: 0.0010\n",
      "Epoch 285/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 107765.9375 - mse: 107765.9375 - val_loss: 61343.8750 - val_mse: 61343.8750 - learning_rate: 0.0010\n",
      "Epoch 286/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 93209.6875 - mse: 93209.6875 - val_loss: 61372.5742 - val_mse: 61372.5742 - learning_rate: 0.0010\n",
      "Epoch 287/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 92526.0625 - mse: 92526.0625 - val_loss: 61259.7461 - val_mse: 61259.7461 - learning_rate: 0.0010\n",
      "Epoch 288/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 97385.2969 - mse: 97385.2969 - val_loss: 61115.7891 - val_mse: 61115.7891 - learning_rate: 0.0010\n",
      "Epoch 289/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 88040.7188 - mse: 88040.7188 - val_loss: 60777.9570 - val_mse: 60777.9570 - learning_rate: 0.0010\n",
      "Epoch 290/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 96629.5625 - mse: 96629.5625 - val_loss: 60621.6289 - val_mse: 60621.6289 - learning_rate: 0.0010\n",
      "Epoch 291/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 87862.7578 - mse: 87862.7578 - val_loss: 60626.5820 - val_mse: 60626.5820 - learning_rate: 0.0010\n",
      "Epoch 292/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 101731.1719 - mse: 101731.1719 - val_loss: 60593.5859 - val_mse: 60593.5859 - learning_rate: 0.0010\n",
      "Epoch 293/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 87070.1406 - mse: 87070.1406 - val_loss: 60664.3164 - val_mse: 60664.3164 - learning_rate: 0.0010\n",
      "Epoch 294/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 94420.9297 - mse: 94420.9297 - val_loss: 60469.8594 - val_mse: 60469.8594 - learning_rate: 0.0010\n",
      "Epoch 295/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 86581.1094 - mse: 86581.1094 - val_loss: 60227.0859 - val_mse: 60227.0859 - learning_rate: 0.0010\n",
      "Epoch 296/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 95901.5078 - mse: 95901.5078 - val_loss: 59968.7070 - val_mse: 59968.7070 - learning_rate: 0.0010\n",
      "Epoch 297/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 103367.5781 - mse: 103367.5781 - val_loss: 59855.9375 - val_mse: 59855.9375 - learning_rate: 0.0010\n",
      "Epoch 298/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 98319.6172 - mse: 98319.6172 - val_loss: 59793.3281 - val_mse: 59793.3281 - learning_rate: 0.0010\n",
      "Epoch 299/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 104717.7031 - mse: 104717.7031 - val_loss: 59947.8320 - val_mse: 59947.8320 - learning_rate: 0.0010\n",
      "Epoch 300/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 89700.3281 - mse: 89700.3281 - val_loss: 59881.0117 - val_mse: 59881.0117 - learning_rate: 0.0010\n",
      "Epoch 301/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 74235.0078 - mse: 74235.0078 - val_loss: 59871.6211 - val_mse: 59871.6211 - learning_rate: 0.0010\n",
      "Epoch 302/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 96641.8047 - mse: 96641.8047 - val_loss: 59617.9844 - val_mse: 59617.9844 - learning_rate: 0.0010\n",
      "Epoch 303/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 79853.1250 - mse: 79853.1250 - val_loss: 59461.3555 - val_mse: 59461.3555 - learning_rate: 0.0010\n",
      "Epoch 304/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 84580.1875 - mse: 84580.1875 - val_loss: 59381.7461 - val_mse: 59381.7461 - learning_rate: 0.0010\n",
      "Epoch 305/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 82719.1953 - mse: 82719.1953 - val_loss: 59344.6953 - val_mse: 59344.6953 - learning_rate: 0.0010\n",
      "Epoch 306/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 91199.0312 - mse: 91199.0312 - val_loss: 59408.1914 - val_mse: 59408.1953 - learning_rate: 0.0010\n",
      "Epoch 307/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 83652.3359 - mse: 83652.3359 - val_loss: 59398.3594 - val_mse: 59398.3594 - learning_rate: 0.0010\n",
      "Epoch 308/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 87337.2500 - mse: 87337.2500 - val_loss: 59247.9297 - val_mse: 59247.9297 - learning_rate: 0.0010\n",
      "Epoch 309/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 91863.1328 - mse: 91863.1328 - val_loss: 59198.9688 - val_mse: 59198.9688 - learning_rate: 0.0010\n",
      "Epoch 310/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 82608.6016 - mse: 82608.6016 - val_loss: 59241.2070 - val_mse: 59241.2070 - learning_rate: 0.0010\n",
      "Epoch 311/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 79041.5938 - mse: 79041.5938 - val_loss: 59183.8164 - val_mse: 59183.8164 - learning_rate: 0.0010\n",
      "Epoch 312/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 91494.1250 - mse: 91494.1250 - val_loss: 58968.8789 - val_mse: 58968.8789 - learning_rate: 0.0010\n",
      "Epoch 313/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 69206.5859 - mse: 69206.5859 - val_loss: 58753.1758 - val_mse: 58753.1758 - learning_rate: 0.0010\n",
      "Epoch 314/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 92362.0938 - mse: 92362.0938 - val_loss: 58672.9961 - val_mse: 58673.0000 - learning_rate: 0.0010\n",
      "Epoch 315/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 97514.8438 - mse: 97514.8438 - val_loss: 58526.1836 - val_mse: 58526.1914 - learning_rate: 0.0010\n",
      "Epoch 316/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 94486.8594 - mse: 94486.8594 - val_loss: 58464.1914 - val_mse: 58464.1914 - learning_rate: 0.0010\n",
      "Epoch 317/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 78787.1016 - mse: 78787.1016 - val_loss: 58451.9375 - val_mse: 58451.9375 - learning_rate: 0.0010\n",
      "Epoch 318/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 97792.5156 - mse: 97792.5156 - val_loss: 58465.5664 - val_mse: 58465.5664 - learning_rate: 0.0010\n",
      "Epoch 319/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 98138.3594 - mse: 98138.3594 - val_loss: 58399.4375 - val_mse: 58399.4336 - learning_rate: 0.0010\n",
      "Epoch 320/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 93557.3828 - mse: 93557.3828 - val_loss: 58168.0547 - val_mse: 58168.0547 - learning_rate: 0.0010\n",
      "Epoch 321/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 90633.5469 - mse: 90633.5469 - val_loss: 58159.5156 - val_mse: 58159.5234 - learning_rate: 0.0010\n",
      "Epoch 322/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 91625.4609 - mse: 91625.4609 - val_loss: 58204.6250 - val_mse: 58204.6250 - learning_rate: 0.0010\n",
      "Epoch 323/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 89356.3516 - mse: 89356.3516 - val_loss: 58197.6055 - val_mse: 58197.6055 - learning_rate: 0.0010\n",
      "Epoch 324/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 98465.9766 - mse: 98465.9766 - val_loss: 57957.3633 - val_mse: 57957.3633 - learning_rate: 0.0010\n",
      "Epoch 325/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 96707.0078 - mse: 96707.0078 - val_loss: 58067.2109 - val_mse: 58067.2148 - learning_rate: 0.0010\n",
      "Epoch 326/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 82749.9531 - mse: 82749.9531 - val_loss: 58257.6992 - val_mse: 58257.6992 - learning_rate: 0.0010\n",
      "Epoch 327/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 90857.3047 - mse: 90857.3047 - val_loss: 58101.1367 - val_mse: 58101.1367 - learning_rate: 0.0010\n",
      "Epoch 328/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 90619.3516 - mse: 90619.3516 - val_loss: 58058.7227 - val_mse: 58058.7227 - learning_rate: 0.0010\n",
      "Epoch 329/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 84168.3125 - mse: 84168.3125 - val_loss: 57996.9766 - val_mse: 57996.9766 - learning_rate: 0.0010\n",
      "Epoch 330/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 83326.1016 - mse: 83326.1016 - val_loss: 57761.1289 - val_mse: 57761.1328 - learning_rate: 0.0010\n",
      "Epoch 331/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 96221.2734 - mse: 96221.2734 - val_loss: 57376.7227 - val_mse: 57376.7227 - learning_rate: 0.0010\n",
      "Epoch 332/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 105296.5156 - mse: 105296.5156 - val_loss: 57175.5117 - val_mse: 57175.5117 - learning_rate: 0.0010\n",
      "Epoch 333/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 78531.6406 - mse: 78531.6406 - val_loss: 57077.3672 - val_mse: 57077.3672 - learning_rate: 0.0010\n",
      "Epoch 334/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 89494.3281 - mse: 89494.3281 - val_loss: 57091.1914 - val_mse: 57091.1914 - learning_rate: 0.0010\n",
      "Epoch 335/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 90427.6719 - mse: 90427.6719 - val_loss: 57347.1602 - val_mse: 57347.1602 - learning_rate: 0.0010\n",
      "Epoch 336/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 86386.9062 - mse: 86386.9141 - val_loss: 57538.6719 - val_mse: 57538.6719 - learning_rate: 0.0010\n",
      "Epoch 337/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 81150.1016 - mse: 81150.1016 - val_loss: 57427.6562 - val_mse: 57427.6562 - learning_rate: 0.0010\n",
      "Epoch 338/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 86525.9062 - mse: 86525.8984 - val_loss: 57213.1289 - val_mse: 57213.1289 - learning_rate: 0.0010\n",
      "Epoch 339/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 77905.1641 - mse: 77905.1641 - val_loss: 57159.9336 - val_mse: 57159.9336 - learning_rate: 0.0010\n",
      "Epoch 340/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 90747.1094 - mse: 90747.1094 - val_loss: 56937.0703 - val_mse: 56937.0703 - learning_rate: 0.0010\n",
      "Epoch 341/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 87432.0391 - mse: 87432.0391 - val_loss: 56922.8984 - val_mse: 56922.8984 - learning_rate: 0.0010\n",
      "Epoch 342/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 88821.5859 - mse: 88821.5938 - val_loss: 56865.7344 - val_mse: 56865.7344 - learning_rate: 0.0010\n",
      "Epoch 343/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 87733.0391 - mse: 87733.0391 - val_loss: 56888.1914 - val_mse: 56888.1914 - learning_rate: 0.0010\n",
      "Epoch 344/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 80804.0078 - mse: 80804.0078 - val_loss: 56825.0117 - val_mse: 56825.0039 - learning_rate: 0.0010\n",
      "Epoch 345/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 85905.4375 - mse: 85905.4375 - val_loss: 56494.3867 - val_mse: 56494.3867 - learning_rate: 0.0010\n",
      "Epoch 346/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 100812.9609 - mse: 100812.9609 - val_loss: 56218.9531 - val_mse: 56218.9531 - learning_rate: 0.0010\n",
      "Epoch 347/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 91454.4844 - mse: 91454.4844 - val_loss: 55988.3242 - val_mse: 55988.3242 - learning_rate: 0.0010\n",
      "Epoch 348/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 74462.7891 - mse: 74462.7891 - val_loss: 55915.7695 - val_mse: 55915.7695 - learning_rate: 0.0010\n",
      "Epoch 349/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 79993.1094 - mse: 79993.1094 - val_loss: 55930.8281 - val_mse: 55930.8281 - learning_rate: 0.0010\n",
      "Epoch 350/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 87798.5312 - mse: 87798.5312 - val_loss: 56031.0000 - val_mse: 56031.0000 - learning_rate: 0.0010\n",
      "Epoch 351/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 91824.5938 - mse: 91824.5938 - val_loss: 55858.8008 - val_mse: 55858.8008 - learning_rate: 0.0010\n",
      "Epoch 352/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 76041.2344 - mse: 76041.2344 - val_loss: 55575.0391 - val_mse: 55575.0391 - learning_rate: 0.0010\n",
      "Epoch 353/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 83317.8672 - mse: 83317.8672 - val_loss: 55570.7734 - val_mse: 55570.7734 - learning_rate: 0.0010\n",
      "Epoch 354/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 89711.3828 - mse: 89711.3828 - val_loss: 55480.3164 - val_mse: 55480.3242 - learning_rate: 0.0010\n",
      "Epoch 355/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 98890.6328 - mse: 98890.6328 - val_loss: 55414.1211 - val_mse: 55414.1211 - learning_rate: 0.0010\n",
      "Epoch 356/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 88595.0625 - mse: 88595.0625 - val_loss: 55346.7305 - val_mse: 55346.7305 - learning_rate: 0.0010\n",
      "Epoch 357/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 83164.0469 - mse: 83164.0469 - val_loss: 55317.7383 - val_mse: 55317.7344 - learning_rate: 0.0010\n",
      "Epoch 358/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 80024.8203 - mse: 80024.8125 - val_loss: 55246.4688 - val_mse: 55246.4727 - learning_rate: 0.0010\n",
      "Epoch 359/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 80265.5781 - mse: 80265.5781 - val_loss: 55105.0820 - val_mse: 55105.0820 - learning_rate: 0.0010\n",
      "Epoch 360/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 76779.0859 - mse: 76779.0859 - val_loss: 55089.2969 - val_mse: 55089.2969 - learning_rate: 0.0010\n",
      "Epoch 361/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 92109.5234 - mse: 92109.5234 - val_loss: 54947.6875 - val_mse: 54947.6875 - learning_rate: 0.0010\n",
      "Epoch 362/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 71687.7344 - mse: 71687.7344 - val_loss: 54670.4297 - val_mse: 54670.4297 - learning_rate: 0.0010\n",
      "Epoch 363/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 81670.7891 - mse: 81670.7891 - val_loss: 54523.8594 - val_mse: 54523.8594 - learning_rate: 0.0010\n",
      "Epoch 364/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 95647.7812 - mse: 95647.7812 - val_loss: 54365.2969 - val_mse: 54365.2969 - learning_rate: 0.0010\n",
      "Epoch 365/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 86193.7656 - mse: 86193.7656 - val_loss: 54304.0000 - val_mse: 54304.0000 - learning_rate: 0.0010\n",
      "Epoch 366/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 83504.9219 - mse: 83504.9219 - val_loss: 54108.5391 - val_mse: 54108.5391 - learning_rate: 0.0010\n",
      "Epoch 367/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 81822.0859 - mse: 81822.0781 - val_loss: 54020.4648 - val_mse: 54020.4648 - learning_rate: 0.0010\n",
      "Epoch 368/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 87996.1875 - mse: 87996.1875 - val_loss: 53920.7773 - val_mse: 53920.7773 - learning_rate: 0.0010\n",
      "Epoch 369/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 79457.4922 - mse: 79457.4922 - val_loss: 54302.1914 - val_mse: 54302.1914 - learning_rate: 0.0010\n",
      "Epoch 370/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 93211.0781 - mse: 93211.0781 - val_loss: 54379.3398 - val_mse: 54379.3398 - learning_rate: 0.0010\n",
      "Epoch 371/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 81892.4219 - mse: 81892.4219 - val_loss: 54232.5703 - val_mse: 54232.5781 - learning_rate: 0.0010\n",
      "Epoch 372/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 77934.8750 - mse: 77934.8750 - val_loss: 54132.1953 - val_mse: 54132.1953 - learning_rate: 0.0010\n",
      "Epoch 373/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 79987.7266 - mse: 79987.7266 - val_loss: 54331.9492 - val_mse: 54331.9492 - learning_rate: 0.0010\n",
      "Epoch 374/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 81898.1641 - mse: 81898.1641 - val_loss: 54271.6367 - val_mse: 54271.6367 - learning_rate: 0.0010\n",
      "Epoch 375/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 75849.2266 - mse: 75849.2266 - val_loss: 54102.5938 - val_mse: 54102.5898 - learning_rate: 0.0010\n",
      "Epoch 376/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 74157.9219 - mse: 74157.9219 - val_loss: 53899.4141 - val_mse: 53899.4141 - learning_rate: 0.0010\n",
      "Epoch 377/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 80288.5234 - mse: 80288.5234 - val_loss: 54073.8438 - val_mse: 54073.8398 - learning_rate: 0.0010\n",
      "Epoch 378/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 90754.3750 - mse: 90754.3750 - val_loss: 54257.7461 - val_mse: 54257.7461 - learning_rate: 0.0010\n",
      "Epoch 379/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 85727.0938 - mse: 85727.0938 - val_loss: 54401.8750 - val_mse: 54401.8750 - learning_rate: 0.0010\n",
      "Epoch 380/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 96103.6406 - mse: 96103.6406 - val_loss: 54588.0430 - val_mse: 54588.0430 - learning_rate: 0.0010\n",
      "Epoch 381/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 77607.4531 - mse: 77607.4531 - val_loss: 54632.8633 - val_mse: 54632.8555 - learning_rate: 0.0010\n",
      "Epoch 382/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 91393.8828 - mse: 91393.8906 - val_loss: 54749.0859 - val_mse: 54749.0859 - learning_rate: 0.0010\n",
      "Epoch 383/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 87308.8359 - mse: 87308.8359 - val_loss: 54726.8047 - val_mse: 54726.8047 - learning_rate: 0.0010\n",
      "Epoch 384/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 81652.0234 - mse: 81652.0234 - val_loss: 54810.5039 - val_mse: 54810.5039 - learning_rate: 0.0010\n",
      "Epoch 385/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 85878.7109 - mse: 85878.7109 - val_loss: 54881.5859 - val_mse: 54881.5859 - learning_rate: 0.0010\n",
      "Epoch 386/700\n",
      "\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 77725.1016 - mse: 77725.1016 \n",
      "Epoch 386: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 79490.0859 - mse: 79490.0859 - val_loss: 54822.6680 - val_mse: 54822.6719 - learning_rate: 0.0010\n",
      "Epoch 387/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 86004.1562 - mse: 86004.1562 - val_loss: 54865.7773 - val_mse: 54865.7773 - learning_rate: 5.0000e-04\n",
      "Epoch 388/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 87870.0859 - mse: 87870.0859 - val_loss: 54936.8203 - val_mse: 54936.8203 - learning_rate: 5.0000e-04\n",
      "Epoch 389/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 72752.3047 - mse: 72752.3047 - val_loss: 54919.1406 - val_mse: 54919.1406 - learning_rate: 5.0000e-04\n",
      "Epoch 390/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 74970.1094 - mse: 74970.1094 - val_loss: 54843.4922 - val_mse: 54843.4922 - learning_rate: 5.0000e-04\n",
      "Epoch 391/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 81581.0859 - mse: 81581.0859 - val_loss: 54661.9883 - val_mse: 54661.9883 - learning_rate: 5.0000e-04\n",
      "Epoch 392/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 83133.7812 - mse: 83133.7812 - val_loss: 54693.1914 - val_mse: 54693.1914 - learning_rate: 5.0000e-04\n",
      "Epoch 393/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 79071.1328 - mse: 79071.1328 - val_loss: 54709.7188 - val_mse: 54709.7188 - learning_rate: 5.0000e-04\n",
      "Epoch 394/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 92034.6797 - mse: 92034.6797 - val_loss: 54599.2578 - val_mse: 54599.2578 - learning_rate: 5.0000e-04\n",
      "Epoch 395/700\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 76457.3906 - mse: 76457.3906 - val_loss: 54520.4570 - val_mse: 54520.4570 - learning_rate: 5.0000e-04\n",
      "Epoch 396/700\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 98963.0234 - mse: 98963.0234\n",
      "Epoch 396: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 86922.3984 - mse: 86922.3984 - val_loss: 54511.9023 - val_mse: 54511.9102 - learning_rate: 5.0000e-04\n",
      "Epoch 396: early stopping\n",
      "Restoring model weights from the end of the best epoch: 376.\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000015E6AC48F40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Mean Absolute Error: 162.63912494094282\n",
      "Mean Squared Error: 52064.193390930195\n",
      "R-squared: 0.6771816885542277\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=X_train.shape[1])) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(units=4, activation='relu')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(1, activation='linear'))  \n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  \n",
    "    factor=0.5,  \n",
    "    patience=10,  \n",
    "    min_lr=1e-6,  \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "final = model.fit(X_train, y_train, validation_split=0.33, batch_size=50, epochs=700, callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 53.57\n",
      "Mean Squared Error: 7711.25\n",
      "R^2 Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
